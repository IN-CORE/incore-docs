{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galveston Testbed Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background:\n",
    "Galveston Island is a barrier island located southeast of Houston, TX. The region has been repeatedly impacted by coastal storms and flood hazards, and has a population that is racially and ethnically diverse, with a wide income distribution. This testbed was created to provide an opportunity to: \n",
    "\n",
    "a)\tInvestigate the multi-hazard surge, wave, inundation, and wind hazards in coastal settings.\n",
    "\n",
    "b)\tConsider interdependent infrastructure systems including buildings, transportation, and power.\n",
    "\n",
    "c)\tLeverage historical social-scientific data, informing population dislocation and recovery modeling. \n",
    "\n",
    "d)\tEvaluate hybrid metrics of community resilience, such as those that require coupled modeling between social and physical systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures for Pyincore Notebook/Galveston.png\">\n",
    "<h1><center>Galveston Island, Texas, USA</center></h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current notebook is a **WORK-IN-PROGRESS** that consists of the following modules:\n",
    "\n",
    "a)\tFlood Surge, Wave, and Inundation Models \n",
    "\n",
    "b)\tGalveston Building Damage Analysis \n",
    "\n",
    "c)\tGalveston Household Unit Allocation\n",
    "\n",
    "d)\tGalveston Population Dislocation Model based on Hurricane IKE\n",
    "\n",
    "Other modules such as road and bridge damage analysis, power system analysis, and network analysis to investigate the connectivity of building clusters to emergency services and power will be added to the Notebook in the near future, as associated models are deployed in INCORE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galveston Building Damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd # For reading in shapefiles\n",
    "import numpy as np\n",
    "import sys # For displaying package versions\n",
    "import os # For managing directories and file paths if drive is mounted\n",
    "\n",
    "from pyincore import IncoreClient, Dataset, FragilityService, MappingSet, DataService\n",
    "from pyincore.analyses.buildingdamage.buildingdamage import BuildingDamage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version  3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:33:30) \n",
      "[Clang 9.0.1 ]\n",
      "pandas version:  1.0.5\n",
      "numpy version:  1.19.0\n"
     ]
    }
   ],
   "source": [
    "# Check package versions - good practice for replication\n",
    "print(\"Python Version \",sys.version)\n",
    "print(\"pandas version: \", pd.__version__)\n",
    "print(\"numpy version: \", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mo/dev/pyincore_app'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check working directory - good practice for relative path access\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful to IN-CORE services. pyIncore version detected: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "client = IncoreClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood Surge, Wave, and Inundation Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Galveston Island was struck by Hurricane Ike in September, 2008, with maximum windspeeds of 49 m/s (95 kts) and storm surge elevations reaching at least +3.5 m (NAVD88) on Galveston Island. A full hindcast of Hurricane Ike’s water levels, and wave conditions along with 2%, 1%, and 0.2% Annual Exceedance Probabilities (AEP) were created using the dynamically coupled versions of the Advanced Circulation (ADCIRC) and Simulating Waves Nearshore (SWAN) models. The hindcast simulation was performed using a high-resolution unstructured mesh of the Texas coast, with coverage of the entire Gulf of Mexico basin, having more than 3.3 million nodes and 6.6 million mesh elements. The data are available in terms of 100-m rasterized files with the following IDs in INCORE:\n",
    "\n",
    "- Hurricane Ike Hindcast: ID:5fa5a228b6429615aeea4410\n",
    "\n",
    "- 2% Annual Exceedance Probability (50-yr return period): ID: 5fa5a83c7e5cdf51ebf1adae\n",
    "\n",
    "- 1% Annual Exceedance Probability (100-yr return period): ID: 5fa5a9497e5cdf51ebf1add2\n",
    "\n",
    "- 0.2% Annual Exceedance Probability  (500-yr return period): ID: 5fa5aa19b6429615aeea4476\n",
    "\n",
    "There is also a hazard scenario generated based on historical data with the following ID: 5f15cd627db08c2ccc4e3bab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The building inventory for Galveston consists of 18962 individual residential households. This inventory is also mappable to housing unit info of 32501 individual households explained later in this notebook. It should be noted that the reason that the building and household data are different in terms of numbers is that each individual building can be composed of a few households. The building inventory consists of three major parameters that are used to estimate the fragility of buildings explained shortly later in this notebook. The three parameters are: \n",
    "\n",
    "a)\tElevation of the lowest horizontal structural member\n",
    "\n",
    "b)\tAge group of the building (1, 2,3, and 4 representing age group pre-1974, 1974–1987, 1987–1995, and 1995– 2008, respectively) \n",
    "\n",
    "c)\tElevation of the building with respect to the ground\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Fragility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fragility model used to estimate failure probability during storm surge events is extracted from:\n",
    "\n",
    "Tomiczek, T. Kennedy, A, and Rogers, S., 2013. Collapse limit state fragilities of wood-framed residences from storm surge and waves during Hurricane Ike. Journal of Waterway, Port, Coastal, and Ocean Engineering, 140(1), pp.43-55.\n",
    "\n",
    "This empirical fragility model was developed based on Hurricane Ike surveys of almost 2000 individual wood-frame buildings coupled with high resolution hindcast of the hurricane. For this study two states of damage, “Collapse” and “Survival” were considered.\n",
    "________________________________________\n",
    "The input parameters to the fragility model are:\n",
    "\n",
    "1) Surge: surge level (m) coming from hazard data\n",
    "\n",
    "2) Hs: Significant wave height (m) coming from hazard data\n",
    "\n",
    "3) LHSM: Elevation of the lowest horizontal structural member (ft) coming from building inventory\n",
    "\n",
    "4) age_group: Age group of the building (1, 2,3, and 4 representing age group pre-1974, 1974–1987, 1987–1995, and 1995– 2008, respectively) coming from building Inventory\n",
    "\n",
    "5) G_elev: Elevation of the building with respect to the ground (m) coming from building inventory\n",
    "________________________________________\n",
    "Output:\n",
    "Pf: probability of failure\n",
    "________________________________________\n",
    "In order to calculate the probability of failure, first we need to estimate the relative surge height compared to the ground level from:\n",
    "𝑑𝑠=𝑆𝑢𝑟𝑔𝑒−𝐺𝑒𝑙𝑒𝑣ds\n",
    "\n",
    "Subsequently, we need to calculate the following parameter\n",
    "\n",
    "𝐹𝐵ℎ𝑠=−(𝑑𝑠+0.7∗𝐻𝑠−𝐿𝐻𝑆𝑀∗0.3048)\n",
    "Note: 0.3048 is to convert ft to m as the inventory data are in ft.\n",
    "\n",
    "Then:\n",
    "\n",
    "For FB_hs>= -2.79*Hs the probability of failure is calculated as:\n",
    "𝑃𝑓=Φ(−3.56+1.52∗𝐻𝑠−1.73∗𝐻𝑠∗𝐹𝐵ℎ𝑠−0.31∗𝐹𝐵2ℎ𝑠−0.141∗𝑎𝑔𝑒2𝑔𝑟𝑜𝑢𝑝)\n",
    "\n",
    "and for FB_hs< -2.79*Hs\n",
    "𝑃𝑓=Φ(−3.56+1.52∗𝐻𝑠+2.42∗𝐹𝐵2ℎ𝑠−0.141∗𝑎𝑔𝑒2𝑔𝑟𝑜𝑢𝑝)\n",
    "Where Φ denotes the Cumulative Density Function (CDF) of standard normal distribution.\n",
    "________________________________________\n",
    "Example:\n",
    "If Surge=3 m, Hs =2 m, LHSM=9 ft, age_group=4; G_elev =1 m\n",
    "Then Pf= 0.2620\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_type = \"hurricane\"\n",
    "hazard_id = \"5f15cd627db08c2ccc4e3bab\"\n",
    "\n",
    "bldg_dataset_id = \"60354b6c123b4036e6837ef7\"\n",
    "# Hurricane Building Fragility Mapping\n",
    "#mapping_id = \"602c381a1d85547cdc9f0675\" # prod\n",
    "\n",
    "#fragility_service = FragilityService(client)  # loading fragility mapping\n",
    "#mapping_set = MappingSet(fragility_service.get_mapping(mapping_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n"
     ]
    }
   ],
   "source": [
    "bldg_dmg = BuildingDamage(client)\n",
    "\n",
    "bldg_dmg.load_remote_input_dataset(\"buildings\", bldg_dataset_id)\n",
    "#bldg_dmg.set_input_dataset(\"dfr3_mapping_set\", mapping_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_name = \"Galveston_bldg_dmg_result\"\n",
    "\n",
    "bldg_dmg.set_parameter(\"result_name\", result_name)\n",
    "bldg_dmg.set_parameter(\"hazard_type\", hazard_type)\n",
    "bldg_dmg.set_parameter(\"hazard_id\", hazard_id)\n",
    "bldg_dmg.set_parameter(\"num_cpu\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Building Damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bldg_dmg.run_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve result dataset\n",
    "#building_dmg_result = bldg_dmg.get_output_dataset('ds_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset to Pandas DataFrame\n",
    "#bdmg_df = result.get_dataframe_from_csv(low_memory=False)\n",
    "\n",
    "# Display top 5 rows of output data\n",
    "#bdmg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galveston Housing Unit Allocation (HUA)\n",
    "\n",
    "Housing Unit Allocation using Galveston Oregon Housing Unit Inventory\n",
    "\n",
    "Here we link high-resolution spatial data on 32501 individual household and housing unit characteristics to residential buildings. Critical for linking socio-economic data within IN-CORE. For evacuation example HUA is required to identify the people that may not evacuate after event.\n",
    "The models come from: Rosenheim, Nathanael, Roberto Guidotti, Paolo Gardoni & Walter Gillis Peacock. (2019). Integration of detailed household and housing unit characteristic data with critical infrastructure for post-hazard resilience modeling. Sustainable and Resilient Infrastructure. doi.org/10.1080/23789689.2019.1681821\n",
    "\n",
    "\n",
    "The Housing Unit Allocation Algorithm can be reviewed within IN-CORE on GitHub. Notebook from https://github.com/IN-CORE/pyincore/tree/develop/pyincore/analyses/housingunitallocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyincore.analyses.housingunitallocation import HousingUnitAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Interdependent Community Description - Galveston, Texas\n",
    "\n",
    "Explore building inventory and social systems. Specifically look at how the building inventory connects with the housing unit inventory using the housing unit allocation.\n",
    "The housing unit allocation method will provide detail demographic characteristics for the community allocated to each structure.\n",
    "\n",
    "To run the HUA Algorithm, three inventory files are required:\n",
    "\n",
    "1.\tHousing Unit Inventory - Based on 2010 US Census Block Level Data\n",
    "\n",
    "2.\tAddress Point Inventory - A list of all possible residential/business address points in a community. Address points are the link between buildings and housing units.\n",
    "\n",
    "3.\tBuilding Inventory - A list of all buildings within a community.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Galveston, TX Housing unit inventory\n",
    "housing_unit_inv = \"5fc6ab1cd2066956f49e7a03\"\n",
    "\n",
    "# Galveston, TX Address point inventory\n",
    "address_point_inv = \"5fc6aadcc38a0722f563392e\"\n",
    "\n",
    "# Galveston, TX Building inventory\n",
    "building_inv = \"60354b6c123b4036e6837ef7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Housing Unit Allocation\n",
    "https://github.com/IN-CORE/incore-docs/blob/master/notebooks/housingunitallocation.ipynb\n",
    "\n",
    "Rosenheim, Nathanael, Roberto Guidotti, Paolo Gardoni & Walter Gillis Peacock. (2019). Integration of detailed household and housing unit characteristic data with critical infrastructure for post-hazard resilience modeling. Sustainable and Resilient Infrastructure. doi.org/10.1080/23789689.2019.1681821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n",
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n",
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create housing allocation \n",
    "hua = HousingUnitAllocation(client)\n",
    "\n",
    "# Load input dataset\n",
    "hua.load_remote_input_dataset(\"housing_unit_inventory\", housing_unit_inv)\n",
    "hua.load_remote_input_dataset(\"address_point_inventory\", address_point_inv)\n",
    "hua.load_remote_input_dataset(\"buildings\", building_inv)\n",
    "\n",
    "# Specify the result name\n",
    "result_name = \"Galveston_HUA\"\n",
    "\n",
    "seed = 1238\n",
    "iterations = 1\n",
    "\n",
    "# Set analysis parameters\n",
    "hua.set_parameter(\"result_name\", result_name)\n",
    "hua.set_parameter(\"seed\", seed)\n",
    "hua.set_parameter(\"iterations\", iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Housing unit allocation analysis\n",
    "hua.run_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addrptid</th>\n",
       "      <th>strctid</th>\n",
       "      <th>archetype</th>\n",
       "      <th>struct_typ</th>\n",
       "      <th>year_built</th>\n",
       "      <th>no_stories</th>\n",
       "      <th>a_stories</th>\n",
       "      <th>b_stories</th>\n",
       "      <th>bsmt_type</th>\n",
       "      <th>sq_foot</th>\n",
       "      <th>...</th>\n",
       "      <th>race</th>\n",
       "      <th>hispan</th>\n",
       "      <th>hispan_flag</th>\n",
       "      <th>vacancy</th>\n",
       "      <th>gqtype</th>\n",
       "      <th>incomegroup</th>\n",
       "      <th>randincome</th>\n",
       "      <th>randomhu</th>\n",
       "      <th>aphumerge</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XREF0628-0065-0000-000AP014</td>\n",
       "      <td>XREF0628-0065-0000-000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>142028.8</td>\n",
       "      <td>0.391309</td>\n",
       "      <td>both</td>\n",
       "      <td>POINT (-94.79252 29.3092)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XREF0628-0065-0000-000AP012</td>\n",
       "      <td>XREF0628-0065-0000-000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>325475.7</td>\n",
       "      <td>0.414422</td>\n",
       "      <td>both</td>\n",
       "      <td>POINT (-94.79252 29.3092)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XREF0628-0065-0000-000AP004</td>\n",
       "      <td>XREF0628-0065-0000-000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>260189.9</td>\n",
       "      <td>0.927559</td>\n",
       "      <td>both</td>\n",
       "      <td>POINT (-94.79252 29.3092)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XREF0628-0065-0000-000AP005</td>\n",
       "      <td>XREF0628-0065-0000-000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>347593.4</td>\n",
       "      <td>0.090391</td>\n",
       "      <td>both</td>\n",
       "      <td>POINT (-94.79252 29.3092)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XREF0628-0065-0000-000AP010</td>\n",
       "      <td>XREF0628-0065-0000-000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>558643.5</td>\n",
       "      <td>0.284164</td>\n",
       "      <td>both</td>\n",
       "      <td>POINT (-94.79252 29.3092)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      addrptid                 strctid  archetype struct_typ  \\\n",
       "0  XREF0628-0065-0000-000AP014  XREF0628-0065-0000-000        NaN         W1   \n",
       "1  XREF0628-0065-0000-000AP012  XREF0628-0065-0000-000        NaN         W1   \n",
       "2  XREF0628-0065-0000-000AP004  XREF0628-0065-0000-000        NaN         W1   \n",
       "3  XREF0628-0065-0000-000AP005  XREF0628-0065-0000-000        NaN         W1   \n",
       "4  XREF0628-0065-0000-000AP010  XREF0628-0065-0000-000        NaN         W1   \n",
       "\n",
       "   year_built  no_stories  a_stories  b_stories  bsmt_type  sq_foot  ...  \\\n",
       "0         NaN         NaN        NaN        NaN        NaN      NaN  ...   \n",
       "1         NaN         NaN        NaN        NaN        NaN      NaN  ...   \n",
       "2         NaN         NaN        NaN        NaN        NaN      NaN  ...   \n",
       "3         NaN         NaN        NaN        NaN        NaN      NaN  ...   \n",
       "4         NaN         NaN        NaN        NaN        NaN      NaN  ...   \n",
       "\n",
       "   race  hispan  hispan_flag  vacancy  gqtype  incomegroup  randincome  \\\n",
       "0   2.0     0.0          2.0        0       0         15.0    142028.8   \n",
       "1   1.0     0.0          1.0        0       0         17.0    325475.7   \n",
       "2   1.0     0.0          1.0        0       0         17.0    260189.9   \n",
       "3   1.0     0.0          1.0        0       0         17.0    347593.4   \n",
       "4   1.0     0.0          1.0        0       0         17.0    558643.5   \n",
       "\n",
       "   randomhu  aphumerge                   geometry  \n",
       "0  0.391309       both  POINT (-94.79252 29.3092)  \n",
       "1  0.414422       both  POINT (-94.79252 29.3092)  \n",
       "2  0.927559       both  POINT (-94.79252 29.3092)  \n",
       "3  0.090391       both  POINT (-94.79252 29.3092)  \n",
       "4  0.284164       both  POINT (-94.79252 29.3092)  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve result dataset\n",
    "hua_result = hua.get_output_dataset(\"result\")\n",
    "\n",
    "# Convert dataset to Pandas DataFrame\n",
    "hua_df = hua_result.get_dataframe_from_csv(low_memory=False)\n",
    "\n",
    "# Display top 5 rows of output data\n",
    "hua_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore results from Housing Unit Allocation\n",
    "\n",
    "Keep observations that are matched to a building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hua_df = hua_df.loc[hua_df['aphumerge'] == 'both']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_aa15f3f2_76be_11eb_a588_acde48001122\" ><caption>Confirm housing unit characteristic by Race and Ethnicity.</caption><thead>    <tr>        <th class=\"index_name level0\" >race</th>        <th class=\"col_heading level0 col0\" >1.0</th>        <th class=\"col_heading level0 col1\" >2.0</th>        <th class=\"col_heading level0 col2\" >3.0</th>        <th class=\"col_heading level0 col3\" >4.0</th>        <th class=\"col_heading level0 col4\" >6.0</th>        <th class=\"col_heading level0 col5\" >7.0</th>        <th class=\"col_heading level0 col6\" >Total</th>    </tr>    <tr>        <th class=\"index_name level0\" >Race Ethnicity</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_aa15f3f2_76be_11eb_a588_acde48001122level0_row0\" class=\"row_heading level0 row0\" >1 White alone, Not Hispanic</th>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row0_col0\" class=\"data row0 col0\" >10912</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row0_col6\" class=\"data row0 col6\" >10912</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa15f3f2_76be_11eb_a588_acde48001122level0_row1\" class=\"row_heading level0 row1\" >2 Black alone, Not Hispanic</th>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row1_col1\" class=\"data row1 col1\" >3607</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row1_col6\" class=\"data row1 col6\" >3607</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa15f3f2_76be_11eb_a588_acde48001122level0_row2\" class=\"row_heading level0 row2\" >3 Other Race, Not Hispanic</th>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row2_col2\" class=\"data row2 col2\" >26</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row2_col3\" class=\"data row2 col3\" >607</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row2_col4\" class=\"data row2 col4\" >4</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row2_col5\" class=\"data row2 col5\" >145</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row2_col6\" class=\"data row2 col6\" >782</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa15f3f2_76be_11eb_a588_acde48001122level0_row3\" class=\"row_heading level0 row3\" >4 Any Race, Hispanic</th>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row3_col0\" class=\"data row3 col0\" >2738</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row3_col1\" class=\"data row3 col1\" >25</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row3_col2\" class=\"data row3 col2\" >57</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row3_col3\" class=\"data row3 col3\" >6</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row3_col4\" class=\"data row3 col4\" >1520</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row3_col5\" class=\"data row3 col5\" >184</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row3_col6\" class=\"data row3 col6\" >4530</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa15f3f2_76be_11eb_a588_acde48001122level0_row4\" class=\"row_heading level0 row4\" >Total</th>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row4_col0\" class=\"data row4 col0\" >13650</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row4_col1\" class=\"data row4 col1\" >3632</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row4_col2\" class=\"data row4 col2\" >83</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row4_col3\" class=\"data row4 col3\" >613</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row4_col4\" class=\"data row4 col4\" >1524</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row4_col5\" class=\"data row4 col5\" >329</td>\n",
       "                        <td id=\"T_aa15f3f2_76be_11eb_a588_acde48001122row4_col6\" class=\"data row4 col6\" >19831</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb438c79210>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hua_df['Race Ethnicity'] = \"0 Vacant HU No Race Ethnicity Data\"\n",
    "hua_df['Race Ethnicity'].notes = \"Identify Race and Ethnicity Housing Unit Characteristics.\"\n",
    "\n",
    "hua_df.loc[(hua_df['race'] == 1) & (hua_df['hispan'] == 0),'Race Ethnicity'] = \"1 White alone, Not Hispanic\"\n",
    "hua_df.loc[(hua_df['race'] == 2) & (hua_df['hispan'] == 0),'Race Ethnicity'] = \"2 Black alone, Not Hispanic\"\n",
    "hua_df.loc[(hua_df['race'].isin([3,4,5,6,7])) & (hua_df['hispan'] == 0),'Race Ethnicity'] = \"3 Other Race, Not Hispanic\"\n",
    "hua_df.loc[(hua_df['hispan'] == 1),'Race Ethnicity'] = \"4 Any Race, Hispanic\"\n",
    "hua_df.loc[(hua_df['gqtype'] >= 1),'Race Ethnicity'] = \"5 Group Quarters no Race Ethnicity Data\"\n",
    "\n",
    "# Check new variable\n",
    "table_title = \"Confirm housing unit characteristic by Race and Ethnicity.\"\n",
    "pd.crosstab(hua_df['Race Ethnicity'], hua_df['race'], \n",
    "            margins=True, margins_name=\"Total\").style.set_caption(table_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_aa1c7f74_76be_11eb_a588_acde48001122\" ><caption>Confirm housing unit characteristic by Race and Ethnicity.</caption><thead>    <tr>        <th class=\"index_name level0\" >hispan</th>        <th class=\"col_heading level0 col0\" >0.0</th>        <th class=\"col_heading level0 col1\" >1.0</th>        <th class=\"col_heading level0 col2\" >Total</th>    </tr>    <tr>        <th class=\"index_name level0\" >Race Ethnicity</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_aa1c7f74_76be_11eb_a588_acde48001122level0_row0\" class=\"row_heading level0 row0\" >1 White alone, Not Hispanic</th>\n",
       "                        <td id=\"T_aa1c7f74_76be_11eb_a588_acde48001122row0_col0\" class=\"data row0 col0\" >10912</td>\n",
       "                        <td id=\"T_aa1c7f74_76be_11eb_a588_acde48001122row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "                        <td id=\"T_aa1c7f74_76be_11eb_a588_acde48001122row0_col2\" class=\"data row0 col2\" >10912</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa1c7f74_76be_11eb_a588_acde48001122level0_row1\" class=\"row_heading level0 row1\" >2 Black alone, Not Hispanic</th>\n",
       "                        <td id=\"T_aa1c7f74_76be_11eb_a588_acde48001122row1_col0\" class=\"data row1 col0\" >3607</td>\n",
       "                        <td id=\"T_aa1c7f74_76be_11eb_a588_acde48001122row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "                        <td id=\"T_aa1c7f74_76be_11eb_a588_acde48001122row1_col2\" class=\"data row1 col2\" >3607</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa1c7f74_76be_11eb_a588_acde48001122level0_row2\" class=\"row_heading level0 row2\" >3 Other Race, Not Hispanic</th>\n",
       "                        <td id=\"T_aa1c7f74_76be_11eb_a588_acde48001122row2_col0\" class=\"data row2 col0\" >782</td>\n",
       "                        <td id=\"T_aa1c7f74_76be_11eb_a588_acde48001122row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "                        <td id=\"T_aa1c7f74_76be_11eb_a588_acde48001122row2_col2\" class=\"data row2 col2\" >782</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa1c7f74_76be_11eb_a588_acde48001122level0_row3\" class=\"row_heading level0 row3\" >4 Any Race, Hispanic</th>\n",
       "                        <td id=\"T_aa1c7f74_76be_11eb_a588_acde48001122row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "                        <td id=\"T_aa1c7f74_76be_11eb_a588_acde48001122row3_col1\" class=\"data row3 col1\" >4530</td>\n",
       "                        <td id=\"T_aa1c7f74_76be_11eb_a588_acde48001122row3_col2\" class=\"data row3 col2\" >4530</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa1c7f74_76be_11eb_a588_acde48001122level0_row4\" class=\"row_heading level0 row4\" >Total</th>\n",
       "                        <td id=\"T_aa1c7f74_76be_11eb_a588_acde48001122row4_col0\" class=\"data row4 col0\" >15301</td>\n",
       "                        <td id=\"T_aa1c7f74_76be_11eb_a588_acde48001122row4_col1\" class=\"data row4 col1\" >4530</td>\n",
       "                        <td id=\"T_aa1c7f74_76be_11eb_a588_acde48001122row4_col2\" class=\"data row4 col2\" >19831</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb439792490>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check new variable\n",
    "table_title = \"Confirm housing unit characteristic by Race and Ethnicity.\"\n",
    "pd.crosstab(hua_df['Race Ethnicity'], hua_df['hispan'], \n",
    "            margins=True, margins_name=\"Total\").style.set_caption(table_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_title = \"Table 1. Housing Unit Characteristics by Race and Ethnicity\"\n",
    "table1 = pd.pivot_table(hua_df, values='numprec', index=['Race Ethnicity'],\n",
    "                              margins = True, margins_name = 'Total',\n",
    "                              aggfunc=[len, np.sum], \n",
    "                              fill_value=0).reset_index().rename(\n",
    "                                                            columns={'len': 'Housing Unit',\n",
    "                                                                     'sum' : 'Population',\n",
    "                                                                     'numprec': 'Count'})\n",
    "\n",
    "varformat = {('Housing Unit','Count'): \"{:,}\", ('Population','Count'): \"{:,}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_aa2423a0_76be_11eb_a588_acde48001122 th {\n",
       "          text-align: center;\n",
       "    }</style><table id=\"T_aa2423a0_76be_11eb_a588_acde48001122\" ><caption>Table 1. Housing Unit Characteristics by Race and Ethnicity</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Race Ethnicity</th>        <th class=\"col_heading level0 col1\" >Housing Unit</th>        <th class=\"col_heading level0 col2\" >Population</th>    </tr>    <tr>        <th class=\"blank level1\" ></th>        <th class=\"col_heading level1 col0\" ></th>        <th class=\"col_heading level1 col1\" >Count</th>        <th class=\"col_heading level1 col2\" >Count</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_aa2423a0_76be_11eb_a588_acde48001122level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row0_col0\" class=\"data row0 col0\" >0 Vacant HU No Race Ethnicity Data</td>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row0_col1\" class=\"data row0 col1\" >12,657</td>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa2423a0_76be_11eb_a588_acde48001122level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row1_col0\" class=\"data row1 col0\" >1 White alone, Not Hispanic</td>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row1_col1\" class=\"data row1 col1\" >10,912</td>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row1_col2\" class=\"data row1 col2\" >21,220</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa2423a0_76be_11eb_a588_acde48001122level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row2_col0\" class=\"data row2 col0\" >2 Black alone, Not Hispanic</td>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row2_col1\" class=\"data row2 col1\" >3,607</td>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row2_col2\" class=\"data row2 col2\" >8,302</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa2423a0_76be_11eb_a588_acde48001122level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row3_col0\" class=\"data row3 col0\" >3 Other Race, Not Hispanic</td>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row3_col1\" class=\"data row3 col1\" >782</td>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row3_col2\" class=\"data row3 col2\" >1,698</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa2423a0_76be_11eb_a588_acde48001122level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row4_col0\" class=\"data row4 col0\" >4 Any Race, Hispanic</td>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row4_col1\" class=\"data row4 col1\" >4,530</td>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row4_col2\" class=\"data row4 col2\" >13,424</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa2423a0_76be_11eb_a588_acde48001122level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row5_col0\" class=\"data row5 col0\" >5 Group Quarters no Race Ethnicity Data</td>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row5_col1\" class=\"data row5 col1\" >13</td>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row5_col2\" class=\"data row5 col2\" >240</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_aa2423a0_76be_11eb_a588_acde48001122level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row6_col0\" class=\"data row6 col0\" >Total</td>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row6_col1\" class=\"data row6 col1\" >32,501</td>\n",
       "                        <td id=\"T_aa2423a0_76be_11eb_a588_acde48001122row6_col2\" class=\"data row6 col2\" >44,884</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb48aea0810>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1.style.set_caption(table_title).format(varformat).set_table_styles([\n",
    "    dict(selector='th', props=[('text-align', 'center')]),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the Housing Unit Allocation has worked\n",
    "Notice that the population count totals for the community should match (pretty closely) data collected for the 2010 Decennial Census.\n",
    "This can be confirmed by going to data.census.gov\n",
    "\n",
    "https://data.census.gov/cedsci/table?q=DECENNIALPL2010.P1&g=1600000US4828068,4837252&tid=DECENNIALSF12010.P1\n",
    "    \n",
    "Differences in the housing unit allocation and the Census count may be due to differences between political boundaries and the building inventory. See Rosenheim et al 2019 for more details.\n",
    "\n",
    "The housing unit allocation, plus the building dresults will become the input for the dislocation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned HUA file as CSV\n",
    "hua_df.to_csv(result_name+str(seed)+'_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galveston Population Dislocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyincore.analyses.populationdislocation import PopulationDislocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing_unit_alloc = \"602d5279b1db9c28aeede1ca\" # dev\n",
    "bg_data = \"603545f2dcda03378087e708\"  # IN-CORE_BGMAP_2021-01-19_GalvestonTX\n",
    "value_loss = \"60354810e379f22e16560dbd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_dis = PopulationDislocation(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n",
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_dis.load_remote_input_dataset(\"block_group_data\", bg_data)\n",
    "pop_dis.load_remote_input_dataset(\"value_poss_param\", value_loss)\n",
    "#pop_dis.load_remote_input_dataset(\"housing_unit_allocation\", housing_unit_alloc)\n",
    "\n",
    "#pop_dis.set_input_dataset(\"building_dmg\", building_dmg_result)\n",
    "pop_dis.set_input_dataset(\"housing_unit_allocation\", hua_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_name = \"galveston-pop-disl-results\"\n",
    "seed = 1111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_dis.set_parameter(\"result_name\", result_name)\n",
    "pop_dis.set_parameter(\"seed\", seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Population Dislocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pop_dis.run_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve result dataset\n",
    "#result = pop_dis.get_output_dataset(\"result\")\n",
    "\n",
    "# Convert dataset to Pandas DataFrame\n",
    "#pd_df = result.get_dataframe_from_csv(low_memory=False)\n",
    "\n",
    "# Display top 5 rows of output data\n",
    "#pd_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
