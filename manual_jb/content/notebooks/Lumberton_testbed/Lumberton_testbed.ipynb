{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "108abca5",
   "metadata": {},
   "source": [
    "# Lumberton Testbed\n",
    "\n",
    "NC Buildings and Infrastructure Flood Damage Analysis\n",
    "\n",
    "## 1. Background\n",
    "\n",
    "Lumberton is a small culturally diverse city with a population of 21,542 according to the most recent United States census estimates. This population mainly settled on the banks of the Lumber River and most of the households are low-medium income with an average $31,899 gross annual income with 39.0% White, 36.7% African American, 12.7% Native American (the Lumbee Tribe), and 6.7% Hispanic/Latino. The below figure shows the physical boundaries of Lumberton with respect to the location of the state of North Carolina and Robeson County.  Buildings locations within the city are shown by the dots of various colors in addition to other collected physical infrastructure. This testbed was created to:\n",
    "\n",
    "1. Laverage the on-going Lumberton longitudinal field study and provide numerical support with models and insightful predections. \n",
    "2. Investigate the impact of flooding on buildings and infrastructure.\n",
    "3. Evaluate a number of mitigation strategies and their impacts on flood damage/loss at the building- and community-level.\n",
    "4. Evaluate hybrid metrics of community resilience, such as those that require coupled modeling between social and physical systems.\n",
    "\n",
    "More information about the testbed and the field study can be found in these publications:\n",
    "1. van de Lindt, J. W., Peacock, W. G., Mitrani-Reiser, J., Rosenheim, N., Deniz, D., Dillard, M. K., Tomiczek, T., Koliou, M., Graettinger, A., Crawford, S., Harrison, K. W., Barbosa, A., Tobin, J., Helgeson, J. F., Peek, L., Memari, M., Sutley, E., Hamideh, S., Gu, D., Cauffman, S. A., and Fung, J. F. (2018). The Lumberton, North Carolina Flood of 2016: A Community Resilience Focused Technical Investigation. https://doi.org/10.6028/NIST.SP.1230\n",
    "2. Van De Lindt, John W., Walter Gillis Peacock, Judith Mitrani-Reiser, Nathanael Rosenheim, Derya Deniz, Maria Dillard, Tori Tomiczek et al. \"Community resilience-focused technical investigation of the 2016 Lumberton, North Carolina, flood: An interdisciplinary approach.\" Natural Hazards Review 21, no. 3 (2020): 04020029.https://doi.org/10.1061/(ASCE)NH.1527-6996.0000387\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c4037a",
   "metadata": {},
   "source": [
    "![image2020-8-4_15-25-21.png](images/image2020-8-4_15-25-21.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c3363",
   "metadata": {},
   "source": [
    "The current notebook is a **WORK-IN-PROGRESS** that consists of the following modules:\n",
    "1. Flood Hazard Modeling for inland communities.\n",
    "2. Flood Damage Analysis for Buildings.\n",
    "3. Household Unit Allocation Modeling.\n",
    "4. Population Dislocation analysis based on Hurricane Matthew in 2016.\n",
    "\n",
    "The models used in this testbed come from:\n",
    "1. Omar M. Nofal, and John W van de Lindt. 2020. “Probabilistic Flood Loss Assessment at the Community Scale: A Case Study of 2016 Flooding in Lumberton, NC.” Journal of Risk and Uncertainty in Engineering Systems, Part A: Civil Engineering, 6(2):1-15 https://doi.org/10.1061/AJRUA6.0001060\n",
    "2. Omar M. Nofal, John W van de Lindt, and Trung Q. Do. 2020. “Multi-Variate and Single-Variable Flood Fragility and Loss Approaches for Buildings.” Journal of Reliability Engineering and System Safety, 12(8), 2277 https://doi.org/10.1016/j.ress.2020.106971\n",
    "3. Omar M. Nofal, and John W van de Lindt. 2020. “Minimal Building Flood Fragility and Loss Function Portfolio for Resilience Analysis at the Community-Level.”  Water, 12(8), 2277 https://doi.org/10.3390/w12082277\n",
    "4. Omar M. Nofal, and John W van de Lindt. 2020. “High-Resolution Approach to Quantify the Impact of Building-Level Flood Risk Mitigation and Adaptation Measures on Flood Losses at the Community-Level.” International Journal of Disaster Risk Reduction. https://doi.org/10.1016/j.ijdrr.2020.101903\n",
    "5. Omar M. Nofal, and John W van de Lindt. 2021. “High-Resolution Flood Risk Approach to Quantify the Impact of Policy Change on Flood Losses at Community-Level.” International Journal of Disaster Risk Reduction. https://doi.org/10.1016/j.ijdrr.2021.102429\n",
    "6. Rosenheim, Nathanael, Roberto Guidotti, Paolo Gardoni & Walter Gillis Peacock. (2019). Integration of detailed household and housing unit characteristic data with critical infrastructure for post-hazard resilience modeling. Sustainable and Resilient Infrastructure. https://doi.org/10.1080/23789689.2019.1681821\n",
    "\n",
    "**Note**: The building inventory used for building damage analysis has a smaller geographic boundary when compared to the housing unit inventory. This is because the building inventory used for the damage analysis above includes the buildings that are exposed to modeled flood hazard for the primary study area (Lumberton, NC). However, the housing unit inventory used for the household allocation includes all of Robeson County. \n",
    "\n",
    "The differences between the building inventory and the housing unit inventory is the reason for the missing (NaN) damage state values in the table at the end of the chapters 3 and 4 where the address points are associated with the buildings outside the building inventory footprint. While these address points are outside of the modeled hazard boundary, which explains that all DSs are equal to NaN, they are important for further socio-economic analysis such as identifying the indirect flood impacts on the population outside the study area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dcb4b3",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "The following modules are necessary to run this notebook. To ensure dependencies are correct, install all modules through **conda**.\n",
    "\n",
    "| Module | Version | Notes |\n",
    "| --- | --- | --- |\n",
    "| pyIncore | =>1.3.0 | see: https://incore.ncsa.illinois.edu/doc/incore/install_pyincore.html |\n",
    "| pyIncore_viz | =>1.5.0 | see: https://incore.ncsa.illinois.edu/doc/pyincore_viz/index.html |\n",
    "| matplotlib | 3.1.2 | used for plotting results |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11abff8",
   "metadata": {},
   "source": [
    "## 2. Building Damage Analysis\n",
    "The following code is preparing the IN-CORE analysis by checking versions and connecting to IN-CORE web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0c1f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyincore import IncoreClient, Dataset, FragilityService, MappingSet, DataService\n",
    "from pyincore.analyses.buildingdamage import BuildingDamage\n",
    "from pyincore.analyses.cumulativebuildingdamage import CumulativeBuildingDamage\n",
    "from pyincore.analyses.montecarlofailureprobability import MonteCarloFailureProbability\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd # For reading in shapefiles\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "import sys # For displaying package versions\n",
    "import os # For managing directories and file paths if drive is mounted\n",
    "\n",
    "from pyincore_viz.geoutil import GeoUtil as viz\n",
    "from pyincore_viz.plotutil import PlotUtil as plot\n",
    "\n",
    "client = IncoreClient()\n",
    "client.clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272d8c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data_service object for loading files\n",
    "data_service = DataService(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28495888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check package versions - good practice for replication\n",
    "print(\"Python Version \",sys.version)\n",
    "print(\"pandas version: \", pd.__version__)\n",
    "print(\"numpy version: \", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40224f32",
   "metadata": {},
   "source": [
    "### 2.1 Flood Hazard Modeling\n",
    "Hydrologic and hydrodynamic models were developed to model the flood hazard. The hydrologic analysis was conducted on HEC-HMS using the morphological data (e.g., land use, soil data), precipitation data (measured by National Weather Service), basin characteristics (a high-resolution Digital Elevation Map (DEM)), and data calibration (using the measured stream hydrograph). The hydrodynamic analysis was conducted on HEC-RAS using a high-resolution DEM (1.5m pixel size) provided by NOAA and the hydrographs (discharge-time relationship) provided by USGS. A smaller than usual mesh size (20m x 20m) was used to model the 2-D flow area to ensure the effect of levees and other hydraulic structures can be accurately accounted for in the models. A scenario-based hazard model was used based on the rainfall event after the 2016 Hurricane Matthew. A raster map of the developed flood hazard and the evolution of the flooding event are shown in the below figure. The hazard data are available in terms of scenario-based with the following IDs in IN-CORE:\n",
    "\n",
    "* The flooding event after hurricane Matthew in 2016 ID: 5f5916456f515f55ee30a5f0\n",
    "* The flood depth measured from ground elevation ID: 5f59163b96a72270bcb81c58\n",
    "* The Water Surface Elevation (WSE) ID: 5f59163f96a72270bcb81c5c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a6184d",
   "metadata": {},
   "source": [
    "![image2020-8-4_16-20-45.png](images/image2020-8-4_16-20-45.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4c86f6",
   "metadata": {},
   "source": [
    "The following code reads the flood hazard data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d803bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flood Inundation Hazard Map based on the flooding event after Hurricane Matthew in 2016 from IN-CORE\n",
    "hazard_type = \"flood\"\n",
    "Flood_Inundation_Depth_ft_id = \"5f59163b96a72270bcb81c58\"   # Raster Map for the flood inundation depth in ft\n",
    "\n",
    "#visualize the Flood Inundation hazard data \n",
    "Flood_Inundation_Depth_ft_dataset = Dataset.from_data_service(Flood_Inundation_Depth_ft_id, DataService(client))\n",
    "viz.map_raster_overlay_from_file(Flood_Inundation_Depth_ft_dataset.get_file_path('tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aeb57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Flood WSE Hazard Map based on the flooding event after Hurricane Matthew in 2016 from IN-CORE\n",
    "hazard_type = \"flood\"\n",
    "Flood_WSE_ft_id = \"5f59163f96a72270bcb81c5c\"   # Raster Map for the flood WSE measured from the mean sea level in ft\n",
    "\n",
    "#visualize the Flood WSE hazard data \n",
    "Flood_WSE_ft_dataset = Dataset.from_data_service(Flood_WSE_ft_id, DataService(client))\n",
    "viz.map_raster_overlay_from_file(Flood_WSE_ft_dataset.get_file_path('tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d201506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Hazard type and the Hazard ID\n",
    "hazard_type = \"flood\"\n",
    "hazard_id = \"5f5916456f515f55ee30a5f0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c08f328",
   "metadata": {},
   "source": [
    "### 2.2 Exposure Modeling\n",
    "Building sectors within a community including the residential sector, commercial/business sector, and social institutions (e.g. schools, hospitals) were divided into 15 building archetypes as shown in the below figure. Table (1) also shows a list of these archetypes along with a brief description for each one. These archetypes are intended to provide a reasonable representation of the buildings within a  small to middle size community. These archetypes were selected by navigating more than 20,000 buildings within a typical eastern U.S. community using Google Street Map view and field-surveying a number of these buildings during the Lumberton longitudinal Field study. The assumed building size and shape can be modified to match other sizes and shapes of buildings as needed to ensure loss calculations are proportional to building size, so simple multipliers can provide relatively straight forward expansion of the archetype portfolio for more accuracy. The below table shows a briefe description about each one of these archetypes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dd2035",
   "metadata": {},
   "source": [
    "![image2020-8-4_16-55-13.png](images/image2020-8-4_16-55-13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ddf8a",
   "metadata": {},
   "source": [
    "![Capture.png](images/Capture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2749af",
   "metadata": {},
   "source": [
    "The following code reads the building inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2286399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lumberton Building Inventory from IN-CORE\n",
    "Building_Inventory_id = \"6036c2a9e379f22e1658d451\"\n",
    "\n",
    "# visualize the building inventory\n",
    "Lumberton_Building_Inventory = Dataset.from_data_service(Building_Inventory_id, DataService(client))\n",
    "viz.plot_map(Lumberton_Building_Inventory, column=\"archetype\", category=True, basemap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6e8a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load building inventory as Geodataframe\n",
    "filename = Lumberton_Building_Inventory.get_file_path('shp')\n",
    "print(\"The IN-CORE Dataservice has saved the Building Inventory on your local machine: \"+filename)\n",
    "bldg_inv_gdf = gpd.read_file(filename)\n",
    "bldg_inv_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e9570e",
   "metadata": {},
   "source": [
    "### 2.3 Fragility-Based Vulnerability Modeling\n",
    "A single-variable and multi-variate flood fragility and loss functions are developed for the 15 building archetypes. Each building archetype was divided into a set of components. For each component, the upper and lower bounds for the flood depth and flood duration that result in damage were used to develop 1000 normally distributed random samples for each component in between these bounds. Some of the upper and lower bounds for the components damaging flood depth and flood duration were collected from the literature and some of them were collected from online sources and others were assumed using the best engineering judgment. MCS was used to account for the components loss and failure probability for each component at each intensity measure (flood depth and flood duration) using the below equations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d563eff9",
   "metadata": {},
   "source": [
    "![image2020-8-4_17-32-6.png](images/image2020-8-4_17-32-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fb00d4",
   "metadata": {},
   "source": [
    "where Frk(IM=x) = fragility function (failure probability at IM=x) for component k, D = component demand, R = component resistance, IM(x) is the intensity measure, nf = number of failed simulations, and N = the total number of simulations. Lk (IM=x) = is the component replacement cost vector at (IM=x), k = component number, Lrik = an i th random simulation of the replacement cost of component k, and Lik = an ith random simulation of the replacement cost for component k at a specified intensity measure (IM=x). µLk (IM=x) = the mean replacement cost of component k at (IM=x), and σLk (IM=x) = the standard deviation of the replacement cost of component k at (IM=x).\n",
    "\n",
    "\n",
    "\n",
    "For buildings fragility functions, a set of performance criteria (damage states) for buildings subjected to flood hazards was developed. These performance criteria describe flood damage to buildings in terms of five damage states (DSs) ranging from insignificant damage (DS0) up to complete damage (DS4) as shown in Table (2). These DSs were designed such that they could describe both building functionality and serviceability in terms of the general building performance based on the behavior of a group of components exposed to a certain hazard intensity, thereby informing damage and the consequent level of occupancy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff24edf",
   "metadata": {},
   "source": [
    "![sadfsa.png](images/sadfsa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c121a4",
   "metadata": {},
   "source": [
    "The exceedance probability of each DS was calculated based on the failure probability of each component within each DS and then weighted by the ratio of the replacement cost of each component to the replacement costs of all damageable components making up that DS using Eq. (5). Then, the calculated fragility was fitted using the lognormal cumulative distribution function (CDF) using Eq. (6). The below figure shows an example of how the exceedance probability of DS4 for a one-story residential building archetype (archetype F2) was derived from its components fragility with lognormal fitted fragility curves as solid lines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1429259b",
   "metadata": {},
   "source": [
    "![image2020-8-4_17-40-29.png](images/image2020-8-4_17-40-29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa6b85",
   "metadata": {},
   "source": [
    "where Lf(IM=x)  = total building fragility-based losses in monetary terms at IM=x (replacement or repair cost), P(DSi | IM=x) = exceedance probability of DSi at IM=x, P(DSi+1) = exceedance probability of DSi+1 at IM=x, Lrci = cumulative replacement cost ratio corresponding to DSi, and Vt = total building cost (replacement cost).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef30750",
   "metadata": {},
   "source": [
    "![image2020-8-4_17-47-40.png](images/image2020-8-4_17-47-40.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639043c2",
   "metadata": {},
   "source": [
    "The lognormal parameters of the 2-D fragility functions are listed in Table (3). Additionally, the data for the 3-D fragility and loss functions are available in an excel format to be uploaded to the IN-CORE web services. It should be mentioned that DS0 only exists for archetypes with a crawlspace foundation which are archetypes F1 and F3. For all building archetypes, flood depth is measured from FFE. However, for the archetypes with crawl space foundation, flood depth is measured from ground elevation and the FFE is assumed to be at 1.0m from the ground elevation which explains why DS1 and DS2 for archetypes F1 and F3 are shifted from the suit of fragilities. Detailed results in terms of six figures for each building archetype (component fragility curves, total building fragility curves, selected components loss curves, total building loss curves, total building fragility surfaces, and total building loss surface) could be found in the references. The resulting fragility and loss functions including the 2-D and 3-D functions are organized into user-friendly matrices such that they can be easily used by researchers or be read by any algorithm to account for flood damage/loss at any intensity measure for any building archetype. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18339922",
   "metadata": {},
   "source": [
    "![dsdfs-2.png](images/dsdfs-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932111ac",
   "metadata": {},
   "source": [
    "The following code maps the fragility functions associated with each building archetype to the building inventory based on the assigned archetype to each building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ddf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flood building archetypes mapping \n",
    "mapping_id = \"602f3cf981bd2c09ad8f4f9d\"\n",
    "fragility_service = FragilityService(client)\n",
    "mapping_set = MappingSet(fragility_service.get_mapping(mapping_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615d265",
   "metadata": {},
   "source": [
    "### 2.4 Building Damage Analysis\n",
    "Hazard, exposure, and vulnerability models were overlaid in a community-level loss/damage analysis framework that enables the flood loss/damage calculation for each building within the community using the framework illustrated in the flow chart in the below flow chart. This study represents the first time that a representative suite of flood fragilities have been utilized to perform community-level damage and loss analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba9c018",
   "metadata": {},
   "source": [
    "![image2020-8-4_21-15-8.png](images/image2020-8-4_21-15-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea086bb",
   "metadata": {},
   "source": [
    "The following code sets up a buidling damage analysis with input datasets and parameters, then runs the analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93312a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "bldg_dmg = BuildingDamage(client)\n",
    "\n",
    "bldg_dmg.load_remote_input_dataset(\"buildings\", Building_Inventory_id)\n",
    "bldg_dmg.set_input_dataset(\"dfr3_mapping_set\", mapping_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d344db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the building damage analysis\n",
    "result_name = \"Lumberton_bldg_flood_dmg_result\"\n",
    "\n",
    "bldg_dmg.set_parameter(\"fragility_key\", \"Lumberton Flood Building Fragility ID Code\")\n",
    "bldg_dmg.set_parameter(\"result_name\", result_name)\n",
    "bldg_dmg.set_parameter(\"hazard_type\", hazard_type)\n",
    "bldg_dmg.set_parameter(\"hazard_id\", hazard_id)\n",
    "bldg_dmg.set_parameter(\"num_cpu\", 4)\n",
    "bldg_dmg.run_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ad754",
   "metadata": {},
   "source": [
    "The following code explores the buildings damage analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f65f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve result dataset\n",
    "building_dmg_result = bldg_dmg.get_output_dataset('ds_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d6c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset to Pandas DataFrame\n",
    "bdmg_df = building_dmg_result.get_dataframe_from_csv(low_memory=False)\n",
    "\n",
    "# Display top 5 rows of output data\n",
    "bdmg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b59a842",
   "metadata": {},
   "source": [
    "## 3. Housing Unit Allocation \n",
    "Housing Unit Allocation using Lumberton, North Carolina Housing Unit Inventory\n",
    "\n",
    "Here we link high-resolution spatial data of all the households in Robeson County, NC and housing unit characteristics to residential buildings which is critical for linking socio-economic data within IN-CORE. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50246f2f",
   "metadata": {},
   "source": [
    "The following code importing the pyincore function used for the Housing Unit Allocation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824580fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyincore.analyses.housingunitallocation import HousingUnitAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d3984d",
   "metadata": {},
   "source": [
    "### 3.1 Initial Interdependent Community Description - Lumberton, NC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6701c4b7",
   "metadata": {},
   "source": [
    "Explore building inventory and social systems. Specifically look at how the building inventory connects with the housing unit inventory using the housing unit allocation. The housing unit allocation method will provide detail demographic characteristics for the community allocated to each structure.\n",
    "\n",
    "To run the HUA Algorithm, three input datasets are required:\n",
    "\n",
    "1. Housing Unit Inventory - Based on 2010 US Census Block Level Data\n",
    "\n",
    "2. Address Point Inventory - A list of all possible residential/business address points in a community. Address points are the link between buildings and housing units.\n",
    "\n",
    "3. Building Inventory - A list of all buildings within a community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d629872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lumberton, NC Housing unit inventory\n",
    "housing_unit_inv = \"60aac3195e52dd415f54e4ff\"\n",
    "# Lumberton, NC Address point inventory\n",
    "address_point_inv = \"60aac382088dfa3b65030b16\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb3270",
   "metadata": {},
   "source": [
    "### 3.2 Set Up and Run Housing Unit Allocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907ff7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create housing allocation\n",
    "hua = HousingUnitAllocation(client)\n",
    "\n",
    "# Load input dataset\n",
    "hua.load_remote_input_dataset(\"housing_unit_inventory\", housing_unit_inv)\n",
    "hua.load_remote_input_dataset(\"address_point_inventory\", address_point_inv)\n",
    "hua.load_remote_input_dataset(\"buildings\", Building_Inventory_id)\n",
    "\n",
    "# Specify the result name\n",
    "result_name = \"Lumberton_HUA\"\n",
    "\n",
    "seed = 1238\n",
    "iterations = 1\n",
    "\n",
    "# Set analysis parameters\n",
    "hua.set_parameter(\"result_name\", result_name)\n",
    "hua.set_parameter(\"seed\", seed)\n",
    "hua.set_parameter(\"iterations\", iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Housing unit allocation analysis\n",
    "hua.run_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fcef62",
   "metadata": {},
   "source": [
    "### 3.3  Explore results from Housing Unit Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85da639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve result dataset\n",
    "hua_result = hua.get_output_dataset(\"result\")\n",
    "\n",
    "# Convert dataset to Pandas DataFrame\n",
    "hua_df = hua_result.get_dataframe_from_csv(low_memory=False)\n",
    "\n",
    "# Display top 5 rows of output data\n",
    "hua_df[['guid','numprec','race','geometry']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43aa1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hua_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb1ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions to add to pyincore-viz\n",
    "\n",
    "def add_race_ethnicity_to_hua_df(df):\n",
    "\n",
    "    df['Race Ethnicity'] = \"0 Vacant HU No Race Ethnicity Data\"\n",
    "    df['Race Ethnicity'].notes = \"Identify Race and Ethnicity Housing Unit Characteristics.\"\n",
    "\n",
    "    df.loc[(df['race'] == 1) & (df['hispan'] == 0),'Race Ethnicity'] = \"1 White alone, Not Hispanic\"\n",
    "    df.loc[(df['race'] == 2) & (df['hispan'] == 0),'Race Ethnicity'] = \"2 Black alone, Not Hispanic\"\n",
    "    df.loc[(df['race'] == 3) & (df['hispan'] == 0),'Race Ethnicity'] = \"3 American Indian and Alaska Native alone, Not Hispanic\"\n",
    "    df.loc[(df['race'] == 4) & (df['hispan'] == 0),'Race Ethnicity'] = \"4 Asian alone, Not Hispanic\"\n",
    "    df.loc[(df['race'].isin([5,6,7])) & (df['hispan'] == 0),'Race Ethnicity'] = \"5 Other Race, Not Hispanic\"\n",
    "    df.loc[(df['hispan'] == 1),'Race Ethnicity'] = \"6 Any Race, Hispanic\"\n",
    "    df.loc[(df['gqtype'] >= 1),'Race Ethnicity'] = \"7 Group Quarters no Race Ethnicity Data\"\n",
    "    # Set Race Ethnicity to missing if structure is vacant - makes tables look nicer\n",
    "    df.loc[(df['Race Ethnicity'] == \"0 Vacant HU No Race Ethnicity Data\"),'Race Ethnicity'] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_tenure_to_hua_df(df):\n",
    "\n",
    "    df['Tenure Status'] = \"0 No Tenure Status\"\n",
    "    df['Tenure Status'].notes = \"Identify Renter and Owner Occupied Housing Unit Characteristics.\"\n",
    "\n",
    "    df.loc[(df['ownershp'] == 1),'Tenure Status'] = \"1 Owner Occupied\"\n",
    "    df.loc[(df['ownershp'] == 2),'Tenure Status'] = \"2 Renter Occupied\"\n",
    "    # Set Tenure Status to missing if structure is vacant - makes tables look nicer\n",
    "    df.loc[(df['Tenure Status'] == \"0 No Tenure Status\"),'Tenure Status'] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_dislocates_pd_df(df):\n",
    "    \"\"\"\n",
    "    Population dislocation requires data on building damage and population charactersitics\n",
    "    If the observation does not have building data then population dislocation \n",
    "    is set to missing.\n",
    "    \n",
    "    \"\"\"\n",
    "    df['Population Dislocation'] = \"No Data\"\n",
    "    df['Population Dislocation'].notes = \"Identify Population Dislocation.\"\n",
    "\n",
    "    df.loc[(df['dislocated'] == False) & (df['guid'].notnull()),'Population Dislocation'] = \"0 Does not dislocate\"\n",
    "    df.loc[(df['dislocated'] == True) & (df['guid'].notnull()),'Population Dislocation'] = \"1 Dislocates\"\n",
    "    # Set Tenure Status to missing if structure is vacant - makes tables look nicer\n",
    "    df.loc[(df['Population Dislocation'] == \"No Data\"),'Population Dislocation'] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_colpercent(df, sourcevar, formatedvar):\n",
    "    df['%'] = (df[sourcevar] / (df[sourcevar].sum()/2)* 100)\n",
    "    df['(%)'] = df.agg('({0[%]:.1f}%)'.format,axis=1)\n",
    "    df['value'] = df[sourcevar]\n",
    "    df['format value'] =  df.agg('{0[value]:,.0f}'.format, axis=1)\n",
    "    df[formatedvar]= df['format value'] + '\\t '+ df['(%)']\n",
    "\n",
    "    df = df.drop(columns=[sourcevar,'%','(%)','value','format value'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Draft function to add link to Census Data - preferable at the bottom of the table\n",
    "def add_linktoCensusData(placeid = '1600000US3739700'):\n",
    "    \"\"\"\n",
    "    I would like to have a source link under the table (left justified)\n",
    "    It might be possible to edit the html code\n",
    "    It might be possible to use display to \"stack\" 2 tables\n",
    "    display(table1)\n",
    "    display(source caption)\n",
    "    \"\"\"\n",
    "    styles = [dict(selector=\"caption\", \n",
    "    props=[(\"text-align\", \"left\"),\n",
    "           (\"caption-side\", \"bottom\"),\n",
    "           (\"font-size\", \"80%\"),\n",
    "           (\"color\", 'black')])]    # the color value can not be None\n",
    "\n",
    "    url = 'https://data.census.gov/cedsci/table?q=DECENNIALPL2010.P5&g='+placeid+'&tid=DECENNIALSF12010.P5'\n",
    "    caption = \"Validate results: <a href=\"+url+\" target='_blank'> US Census Bureau Data Viewer </a>\"\n",
    "\n",
    "    output = df.style.set_table_attributes()\\\n",
    "     .set_caption(caption)\\\n",
    "     .set_table_styles(styles)\n",
    "\n",
    "    \n",
    "    return output\n",
    "\n",
    "def pop_results_table(df, \n",
    "                      who = \"Total Houseohlds\", \n",
    "                      what= \"by Race, Ethncity, and Tenure Status\",\n",
    "                      when = \"2010\", \n",
    "                      where = \"\",\n",
    "                      row_index = 'Race Ethnicity',\n",
    "                      col_index = 'Tenure Status',\n",
    "                      row_percent = ''):\n",
    "    \n",
    "    df = add_race_ethnicity_to_hua_df(df)\n",
    "    df = add_tenure_to_hua_df(df)\n",
    "    \n",
    "    if who == \"Total Houseohlds\":\n",
    "        variable = 'numprec'\n",
    "        function = 'count'\n",
    "        renamecol = {'Total': who, 'sum': ''}\n",
    "        num_format = \"{:,.0f}\"\n",
    "    elif who == \"Total Population\":\n",
    "        variable = 'numprec'\n",
    "        function = np.sum\n",
    "        renamecol = {'Total': who, 'sum': ''}\n",
    "        num_format = \"{:,.0f}\"\n",
    "    elif who == \"Median Household Income\":\n",
    "        variable = 'randincome'\n",
    "        function = np.median\n",
    "        renamecol = {'Total': who}\n",
    "        num_format = \"${:,.0f}\"\n",
    "    else:\n",
    "        variable = 'numprec'\n",
    "        function = 'count'\n",
    "        renamecol = {'Total': who, 'sum': ''}\n",
    "        num_format = \"{:,.0f}\"\n",
    "        \n",
    "    # Generate table\n",
    "    table = pd.pivot_table(df, values=variable, index=[row_index],\n",
    "                           margins = True, margins_name = 'Total',\n",
    "                           columns=[col_index], aggfunc=function).rename(columns=renamecol)\n",
    "    table_title = \"Table. \"+ who +\" \"+ what+\", \"+ where +\", \"+ when +\".\"\n",
    "    varformat = {(who): num_format}\n",
    "    for col in table.columns:\n",
    "        varformat[col] = num_format\n",
    "        \n",
    "    # Add percent row column\n",
    "    if row_percent != '':\n",
    "        numerator = table[row_percent]\n",
    "        denomenator = table[who]\n",
    "        table['row_pct'] = numerator/denomenator * 100\n",
    "        table['Percent Row ' + '\\n' + row_percent] = table.agg('{0[row_pct]:.1f}%'.format,axis=1)\n",
    "        table = table.drop(columns=['row_pct'])\n",
    "    \n",
    "    # Add Column Percents \n",
    "    if who in [\"Total Houseohlds\",\"Total Population\"]:\n",
    "        # add column percent to all columns except the percent row column\n",
    "        row_pct_vars = [col for col in table if col.startswith('Percent Row ')]\n",
    "        columns = [col for col in table if col not in row_pct_vars]\n",
    "        for col in columns:\n",
    "            formated_column_name = col + ' (%)'\n",
    "            table = add_colpercent(table, col, formated_column_name)\n",
    "            \n",
    "    # Move row percent to last column\n",
    "    if row_percent != '':\n",
    "        row_pct_vars = [col for col in table if col.startswith('Percent Row ')]\n",
    "        columns = [col for col in table if col not in row_pct_vars]\n",
    "        table = table[columns + row_pct_vars]\n",
    "        \n",
    "    # To do - add source information (inlcude Census Link with Place ID)\n",
    "    # To do - add provenance option - name of dataset ource and program name\n",
    "        \n",
    "    # Caption Title Style\n",
    "    styles = [dict(selector=\"caption\", \n",
    "        props=[(\"text-align\", \"center\"),\n",
    "               (\"caption-side\", \"top\"),\n",
    "               (\"font-size\", \"150%\"),\n",
    "               (\"color\", 'black')])]    # the color value can not be None\n",
    "    \n",
    "    table = table.style\\\n",
    "     .set_caption(table_title)\\\n",
    "     .set_table_styles(styles)\\\n",
    "     .format(varformat)\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b3b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_results_table(hua_df, where = \"Robeson County NC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd47d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_results_table(hua_df, \n",
    "                  who = \"Total Population\", \n",
    "                  where = \"Robeson County NC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0019cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_results_table(hua_df.loc[hua_df['plcname10']=='Lumberton'].copy(), \n",
    "                  who = \"Total Population\", \n",
    "                  what = \"by Race, Ethncity, and Building Data\",\n",
    "                  where = \"Lumberton NC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e34248c",
   "metadata": {},
   "source": [
    "### 3.4 Validate the Housing Unit Allocation has worked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958bf03f",
   "metadata": {},
   "source": [
    "Notice that the population count totals for the community should match (pretty closely) data collected for the 2010 Decennial Census. This can be confirmed by going to data.census.gov\n",
    "\n",
    "https://data.census.gov/cedsci/table?q=DECENNIALPL2010.H11&g=1600000US3739700&tid=DECENNIALSF12010.H11\n",
    "\n",
    "Differences in the housing unit allocation and the Census count may be due to differences between political boundaries and the building inventory. See Rosenheim et al 2019 for more details.\n",
    "\n",
    "The housing unit allocation, plus the building dresults will become the input for the dislocation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7453aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned HUA file as CSV\n",
    "hua_df.to_csv(result_name + str(seed) + '_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ace39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of buildings that are exposed to flood hazard\n",
    "hua_df[['guid','x','y','race','geometry']][21400:21406]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of buildings outside the floodplain\n",
    "hua_df[['guid','x','y','race','geometry']].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db1eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use shapely.wkt loads to convert WKT to GeoSeries\n",
    "from shapely.geometry import Point\n",
    "# Geodata frame requires geometry and CRS to be set\n",
    "hua_gdf = gpd.GeoDataFrame(\n",
    "    hua_df,\n",
    "    crs=('epsg:4326'),\n",
    "    geometry=[Point(xy) for xy in zip(hua_df['x'], hua_df['y'])])\n",
    "hua_gdf[['guid','x','y','race','geometry']][21400:21406]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733cdeda",
   "metadata": {},
   "source": [
    "### 3.5 Visualize heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5eca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "map = viz.plot_heatmap_from_gdf(hua_gdf, \"numprec\", radius=7, blur=10, name=\"HUA Heatmap\")\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99262707",
   "metadata": {},
   "source": [
    "## 4. Population Dislocation Analysis\n",
    "Population dislocation refers to households that will be forced to leave their pre-event residence due to hazard related damages. Population dislocation is a function of structure value loss due to damage, neighborhood characteristics and structure type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b309cd8",
   "metadata": {},
   "source": [
    "## 4.1 Set Up and Run Population Dislocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2185b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyincore.analyses.populationdislocation import PopulationDislocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca2080",
   "metadata": {},
   "source": [
    "### Use new pyincore-data utility to obtain Block Group Data for County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff1f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyincore_data.censusutil import CensusUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10990dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_counties = ['37155']\n",
    "blockgroup_df, bgmap, outdataset = CensusUtil.get_blockgroupdata_for_dislocation(state_counties, \n",
    "                                                                 out_csv=True, \n",
    "                                                                 out_shapefile=False, \n",
    "                                                                 out_html=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a4c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blockgroup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2180d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lumberton, NC Block group data, IN-CORE_BGMAP_2021-01-19_Lumberton NC\n",
    "# bg_data = \"60b18cb04bed6e6c318b1c9b\" # pyincore-data has created the required dataset locally\n",
    "# Seaside, OR Housing unit allocation, performed at start of notebook\n",
    "bg_data = Dataset.from_file('program_name/program_name_geo_name.csv','incore:blockGroupData')\n",
    "\n",
    "# Value loss parameters DS 0-3\n",
    "value_loss = \"60354810e379f22e16560dbd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0442aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_dis = PopulationDislocation(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2375d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_dis.set_input_dataset(\"block_group_data\", bg_data)\n",
    "pop_dis.load_remote_input_dataset(\"value_loss_param\", value_loss)\n",
    "\n",
    "pop_dis.set_input_dataset(\"building_dmg\", building_dmg_result)\n",
    "pop_dis.set_input_dataset(\"housing_unit_allocation\", hua_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_name = \"Lumberton-pop-disl-results\"\n",
    "seed = 1111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_dis.set_parameter(\"result_name\", result_name)\n",
    "pop_dis.set_parameter(\"seed\", seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_dis.run_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9edbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve result dataset\n",
    "result = pop_dis.get_output_dataset(\"result\")\n",
    "\n",
    "# Convert dataset to Pandas DataFrame\n",
    "pd_df = result.get_dataframe_from_csv(low_memory=False)\n",
    "\n",
    "# Display last 5 rows of output data\n",
    "pd_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3553e763",
   "metadata": {},
   "source": [
    "## 4.2 Explore Population Dislocation Results by Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a61954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file id\n",
    "dataset_id = \"60e5edd3d3c92a78c8940d06\"\n",
    "# load building inventory\n",
    "dataset = Dataset.from_data_service(dataset_id, data_service)\n",
    "filename = dataset.get_file_path('csv')\n",
    "metadata = data_service.get_dataset_metadata(dataset_id = dataset_id)\n",
    "print(\"The IN-CORE Dataservice has saved the dataset titled: \"+metadata['title']+\" on your local machine: \"+filename)\n",
    "print(\"\\nDataset Description: \\n\"+metadata['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "sabs_df = pd.read_csv(filename)\n",
    "sabs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464203c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = pd.merge(pd_df, sabs_df, \n",
    "                        left_on='blockid', right_on='BLOCKID10', how='left')\n",
    "pd_df[['blockid','huid','ncessch_3','high_schnm','ncessch_2','mid_schnm','ncessch_1','primary_schnm']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = add_dislocates_pd_df(pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_results_table(pd_df.loc[pd_df['mid_schnm']=='Lumberton Junior High'].copy(), \n",
    "                  who = \"Total Population\", \n",
    "                  what = \"by Primary School Name, and Population Dislocation Data\",\n",
    "                  where = \"Lumberton Junior High NC\",\n",
    "                  row_index = 'primary_schnm',\n",
    "                  col_index = 'Population Dislocation',\n",
    "                  row_percent = \"1 Dislocates\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
