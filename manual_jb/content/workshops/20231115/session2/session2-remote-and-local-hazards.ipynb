{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc2d2b9",
   "metadata": {},
   "source": [
    "# Session 2: How to Work with Remote and Local Hazards\n",
    "\n",
    "**Objective:**\n",
    "- Learn about the basics of IN-CORE modules and objects.\n",
    "- Learn how to create and use hazards by using pyIncore and IN-CORE web services and how to create and use local hazards.\n",
    "\n",
    "**Agenda**\n",
    "- [1. Basics of IN-CORE modules](#1.-Basics-of-IN-CORE-modules)\n",
    "- [2. Working with Existing Hazards (Tornado and Earthquake)](#2.-Working-with-Existing-Hazards-(Tornado-and-Earthquake))\n",
    "    - [2.1 Tornado hazards](#2.1-Tornado-hazards)\n",
    "        - [2.1.1 Working with an existing tornado](#2.1.1-Working-with-an-existing-tornado)\n",
    "        - [2.1.2 Creating model-based tornado](#2.1.2-Creating-model-based-tornado)\n",
    "        - [2.1.3 Creating a dataset-driven tornado](#2.1.3-Creating-a-dataset-driven-tornado)\n",
    "    - [2.2 Earthquake hazards](#2.2.-Earthquake-hazards)\n",
    "        - [2.2.1 Working with existing earthquake hazards](#2.2.1-Working-with-existing-earthquake-hazards)\n",
    "        - [2.2.2 Creating model-based earthquakes](#2.2.2-Creating-model-based-earthquakes)\n",
    "        - [2.2.3 Creating a dataset-driven earthquake (Probabilistic & Deterministic)](#2.2.3-Creating-a-dataset-driven-earthquake-(Probabilistic-&-Deterministic))\n",
    "- [3. Working with Local Hazards](#3.-Working-with-Local-Hazards)\n",
    "    - [3.1 Basic Operations for Local Hazards](#3.1-Basic-Operations-for-Local-Hazards)\n",
    "        - [3.1.1 Tornadoes](#3.1.1-Tornadoes)\n",
    "        - [3.1.2 Earthquakes](#3.1.2-Earthquakes)\n",
    "        - [3.1.3 Tsunamis](#3.1.3-Tsunamis)\n",
    "        - [3.1.4 Floods](#3.1.4-Floods)\n",
    "        - [3.1.5 Hurricanes](#3.1.5-Hurricanes)\n",
    "    - [3.2 Visualizations for Local Hazards](#3.2-Visualizations-for-Local-Hazards)\n",
    "        - [3.2.1 Plotting a Tornado](#3.2.1-Plotting-a-tornado)\n",
    "        - [3.2.2 Plotting an Earthquake](#3.2.2-Plotting-an-Earthqauke)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41edbef0",
   "metadata": {},
   "source": [
    "## 1. Basics of IN-CORE modules\n",
    "\n",
    "IN-CORE via ```pyincore``` provides a collection of Python classes that wrap the functionality for accessing the IN-CORE web services using Python methods. These classes provide access to Hazards, DFR3 curves, and Data. \n",
    "\n",
    "![pyincore-diagram.png](data/pyincore-diagram.png)\n",
    "\n",
    "To use IN-CORE in Jupyter Notebooks, we start by importing the modules we need.\n",
    "\n",
    "We will first focus on how to effectively use the following modules within the IN-CORE architecture to request information about various hazards:\n",
    "\n",
    "* **IncoreClient:** this entity provides access and authentication to IN-CORE services. To access the services, users\n",
    "  require to have a valid *username* and *password*. Importing ```IncoreClient``` and creating a named instance of the\n",
    "  client is the first step toward using IN-CORE by establishing a remote connection to various simulation and data\n",
    "  access services. The variable containing that instance is used by various other services\n",
    "  to validate the user's identity, as well as provide access to pieces of information required across tasks. *This step\n",
    "  only needs to be done once.*\n",
    "* **HazardService:** once the ```IncoreClient``` has been initiated, the ```HazardService``` module uses the information\n",
    "  from that client to administer existing information about known or new hazards. ```HazardService``` can:\n",
    "  * Retrieve existing metadata for various hazards\n",
    "  * Search hazards per specific information\n",
    "  * Request creation of a new hazard\n",
    "  * Request deletion of a new hazard\n",
    "\n",
    "For more information on **pyincore** modules, see the documentation here: https://incore.ncsa.illinois.edu/doc/pyincore/index.html\n",
    "\n",
    "To begin, let's start by importing a few modules and creating our first IN-CORE objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96403a28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T23:14:55.911896Z",
     "start_time": "2023-11-08T23:14:54.936908Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import json\n",
    "from pyincore import HazardService, IncoreClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad10ca3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T21:56:23.676069Z",
     "start_time": "2023-11-08T21:56:15.382680Z"
    }
   },
   "outputs": [],
   "source": [
    "# Connect to IN-CORE serivce by creating IncoreClient\n",
    "# This only needs to be done once as indicated above\n",
    "client = IncoreClient()\n",
    "\n",
    "# Create a HazardService instance that depends on the client defined in the previous step\n",
    "hazardsvc = HazardService(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe244b",
   "metadata": {},
   "source": [
    "## 2. Working with Existing Hazards (Tornado and Earthquake)\n",
    "### 2.1 Tornado hazards\n",
    " \n",
    "We will start by retrieving existing information about a specific tornado, and then using this information to create a slightly modified new tornado hazard scenario. These scenarios are representative of two of the most frequent tasks with IN-CORE: getting information from existing hazards and the creation of new hazards. We later also construct an example with a database-driven tornado.\n",
    "\n",
    "These two tasks alone can enable decision makers to systematically construct, test and refine scenarios, later to be easily shared and discussed across response teams using Jupyter notebooks such as this.\n",
    "\n",
    "\n",
    "#### 2.1.1 Working with an existing tornado\n",
    "\n",
    "As with any given hazard, IN-CORE operates by utilizing hazard identification strings (*hazard id*) that uniquely\n",
    "name existing scenarios and are associated with data and metadata useful for analysis and visualization purposes.\n",
    "Metadata describe properties of the scenario, such as location and other details of the event.\n",
    "\n",
    "With this identifier, let's perform two tasks:\n",
    "* Obtain metadata about the tornado\n",
    "* Obtain hazard values, often used by decision makers during emergency planning and preparation\n",
    "\n",
    "IN-CORE uses the [JSON lightweight data-interchange format](https://www.json.org/json-en.html) to store and retrieve\n",
    "hazard information across its services as flexible way to share information in a standardized manner. We will use\n",
    "Python's ```json``` module to expand that information in a human-readable format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d0620f",
   "metadata": {},
   "source": [
    "Let's start by using an identifier for one ficticious tornado in Memphis, TN stored as an IN-CORE dataset. We can find hazards on the IN-CORE service by using the hazard viewer here: https://incore.ncsa.illinois.edu/HazardViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9f0fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T18:03:25.404198Z",
     "start_time": "2023-11-03T18:03:25.396506Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example tornado in Memphis, TN (It's an imaginary tornado)\n",
    "example_tornado_id = \"60a44ae8605f0462bd4263ac\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f04afc",
   "metadata": {},
   "source": [
    "Now, using the ```HazardService``` module, we retrieve the metadata and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28be5e7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T18:03:26.963369Z",
     "start_time": "2023-11-03T18:03:26.837856Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tornado_model_metadata = hazardsvc.get_tornado_hazard_metadata(example_tornado_id)\n",
    "print(json.dumps(tornado_model_metadata, indent=4, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a62a75",
   "metadata": {},
   "source": [
    "Using ```pyIncore_viz```, we can now visualize the tornado hazard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b39d1-c0b2-458d-9fe7-b83179f7ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the tornado using pyincore-viz\n",
    "from pyincore_viz.geoutil import GeoUtil as viz\n",
    "viz.plot_tornado(example_tornado_id, client, basemap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07399611-207e-49d9-86a4-56b6d3399b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive map to show the tornado path\n",
    "# hovering mouse over the map shows lat/lon\n",
    "import wsviz\n",
    "wsviz.show_tornado(client, tornado_model_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa92f2f-bf9d-4960-beb4-14ecb8522677",
   "metadata": {},
   "source": [
    "All geographic locations in IN-CORE are specified using the WGS84 coordinate system. Observe that the parameters of the\n",
    "```json.dumps``` function are as follows:\n",
    "\n",
    "* the variable containing the resulting metadata\n",
    "* the indentation used to display the information contained in the JSON format\n",
    "* whether keys are sorted for convenient reading (no in our case)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902d8a57",
   "metadata": {},
   "source": [
    "We will discuss below the meaning of each element in this JSON output in the next section. Using the same service, we can obtain specific\n",
    "data about the hazard, in this case, the hazard values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a1e522",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T18:03:28.606220Z",
     "start_time": "2023-11-03T18:03:28.545294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting hazard value from your model\n",
    "points = [\n",
    "    {\n",
    "        \"demands\": [\"wind\"],\n",
    "        \"units\": [\"mph\"],\n",
    "        \"loc\": \"35.134, -90.031\"\n",
    "    }\n",
    "]\n",
    "\n",
    "tornado_model_vals = hazardsvc.post_tornado_hazard_values(example_tornado_id, points)\n",
    "print(json.dumps(tornado_model_vals, indent=4, sort_keys=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca6ac1-2817-4c70-adde-0baba677842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### QUIZ: Please find the lat/lon of your location on the interactive map\n",
    "### QUIZ: Then, acquire hazard value (wind speed) usin the code example above\n",
    "\n",
    "mypoints = [\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f777368",
   "metadata": {},
   "source": [
    "#### 2.1.2 Creating model-based tornado\n",
    "\n",
    "One of IN-CORE strengths is the ability to specify, execute and retrieve information about new hazard scenarios using\n",
    "the same metadata standard.\n",
    "\n",
    "As promised above, here is a description of each metadata (JSON) element representing a tornado hazard:\n",
    "\n",
    "* **tornadoModel** (required) - the tornado model (Mean width will create a tornado using the mean width from historical data for the EF rating)\n",
    "    * *Mean width tornado (MeanWidthTornado)* - start/end points with a width equal to the average for that EF rating looking at historical tornado data\n",
    "    * *Random width tornado (RandomWidthTornado)* - start/end points, random width selected use the historical data to determine the max width for that tornado rating\n",
    "    * *Mean Length/Width/angle (MeanLengthWidthAngleTornado)* - start point, length/width and angle are based on the historical average for those attributes based on EF selected\n",
    "    * *Random length/width/angle (RandomLengthWidthAngleTornado)* - start point, random length/width/angle selected for the ef rating using historical data\n",
    "    * *Random angle (RandomAngleTornado)* - start point, random angle selected based on historical data.\n",
    "* **efRating (required)** - a value in the Enhanced Fujita (EF) scale intensity of the tornado (EF0 - EF5)\n",
    "* **startLatitude/startLongitude (required)** - the starting location of the tornado\n",
    "* **endLatitude/endLongitude (optional)**- depending on the model, an end latitude/longitude value. Some tornado models (e.g. mean length width, and angle) calcuate endLat and endLon, others (e.g. random angle) will generate multiple endpoints programmatically so the input must be passed as an array\n",
    "* **windSpeedMethod(optional)** - computation of wind speed within an EF boundary, 0 indicates using linear interpolation, 1 indicates uniform random distribution. Default is Uniform random distribution.\n",
    "\n",
    "More information about the tornado models can be found here: https://ascelibrary.org/doi/10.1061/%28ASCE%29NH.1527-6996.0000138\n",
    "\n",
    "As you may already anticipate, the particular JSON elements vary per each hazard type. We call these *parameters*. Some\n",
    "parameters are required (i.e. the analysis cannot be performed without them) and others are\n",
    "\n",
    "##### Random Seeds: about the computational reproducibility of hazard scenarios\n",
    "\n",
    "Ensuring reproducibility of hazard scenarios is paramount for the IN-CORE team due to its scientific and decision-making\n",
    "consequences. Hence, care has been exercised to ensure that scenarios can be re-executed consistently in a standardized\n",
    "and simple manner.\n",
    "\n",
    "Several models (such as this one) require generating pseudo-random numbers to simulate unexpected natural or human\n",
    "effects, computational reproducibility of experiments can become somewhat challenging. IN-CORE harnesses the *random\n",
    "seed*, a special number that determines the exact sequence random number generators (RNGs) produce to ensure\n",
    "repeatability of that sequence independent of where the code is executed. The ```randomSeed``` parameter in IN-CORE\n",
    "takes care of this aspect via an integer value that fixes the random number generating process regardless of when the\n",
    "new analysis is requested or in which infrastructure it is executed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f45c11",
   "metadata": {},
   "source": [
    "##### Defining a new (slightly different) tornado\n",
    "\n",
    "With this information in hand, let's construct a slightly different version of the same tornado. Let us imagine a less\n",
    "intense scenario with a longer trajectory due to conditions that preserve its energy for a longer time. While path\n",
    "length have been reported to increase as their EF rating increases, the case we describe here is plausible (See\n",
    "[On the Relationship of Tornado Path Length and Width to Intensity](https://journals.ametsoc.org/view/journals/wefo/19/2/1520-0434_2004_019_0310_otrotp_2_0_co_2.xml)).\n",
    "\n",
    "To do so, we will vary:\n",
    "* the rating in the Enhanced Fujita (EF) rating from ```\"EF5\"``` to ```\"EF4\"```,\n",
    "* the start and end points to have a longer trajectory,\n",
    "* and the  random number seed to ensure the RNG starts at values different from those in the original scenario.\n",
    "\n",
    "The result of this process is\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"name\": \"Centerville Model Tornado (modified)\",\n",
    "  \"description\": \"Centerville mean width tornado hazard\",\n",
    "  \"tornadoType\": \"model\",\n",
    "  \"tornadoModel\" : \"MeanWidthTornado\",\n",
    "      \"tornadoParameters\" : {\n",
    "      \"efRating\" : \"EF4\",\n",
    "      \"startLatitude\" : \"35.215\",\n",
    "      \"startLongitude\" : \"-97.524\",\n",
    "      \"randomSeed\" : \"3457\",\n",
    "      \"endLatitude\" : [35.253],\n",
    "      \"endLongitude\" : [-97.432],\n",
    "      \"windSpeedMethod\" : \"1\",\n",
    "      \"numSimulations\" : \"1\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "We now proceed to create the model-based tornado with what we have learned so far. We take care to serialize the Python\n",
    "dictionary structure into a JSON specification using ```json.dumps```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62595f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T18:03:37.377534Z",
     "start_time": "2023-11-03T18:03:37.371726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a variable to store the new tornado hazard definition:\n",
    "\n",
    "tornado_model_metadata = {\n",
    "  \"name\": \"Centerville Model Tornado (modified)\",\n",
    "  \"description\": \"Centerville mean width tornado hazard\",\n",
    "  \"tornadoType\": \"model\",\n",
    "  \"tornadoModel\" : \"MeanWidthTornado\",\n",
    "      \"tornadoParameters\" : {\n",
    "      \"efRating\" : \"EF4\",\n",
    "      \"startLatitude\" : \"35.215\",\n",
    "      \"startLongitude\" : \"-97.524\",\n",
    "      \"randomSeed\" : \"3457\",\n",
    "      \"endLatitude\" : [35.253],\n",
    "      \"endLongitude\" : [-97.432],\n",
    "      \"windSpeedMethod\" : \"1\",\n",
    "      \"numSimulations\" : \"1\"\n",
    "    }\n",
    "}\n",
    "\n",
    "tornado_model_json = json.dumps(tornado_model_metadata, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdad819",
   "metadata": {},
   "source": [
    "Now, we create a tornado scenario, and retrieve the *model response* obtained from requesting IN-CORE to process it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875fd95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-03T18:03:40.490527Z",
     "start_time": "2023-11-03T18:03:39.546252Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a tornado with the prior definition\n",
    "model_response = hazardsvc.create_tornado_scenario(tornado_model_json)\n",
    "print(json.dumps(model_response, indent=4, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b6d59f",
   "metadata": {},
   "source": [
    "As with any analysis, we obtain the identifier of the specific response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399aa14f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Acquire hazard id you created\n",
    "tornado_model_id = model_response['id']\n",
    "viz.plot_tornado(tornado_model_id, client, basemap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847120cc-e681-45df-ae72-04e6c39bdb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispaly the path on the interactive map\n",
    "\n",
    "wsviz.show_tornado(client, model_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d07852",
   "metadata": {},
   "source": [
    "As with the first case, we obtain the hazard values for this tornado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1b4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting hazard value from your model based tornado\n",
    "points = [\n",
    "    {\n",
    "        \"demands\": [\"wind\"],\n",
    "        \"units\": [\"mph\"],\n",
    "        \"loc\": \"35.215, -97.521\"\n",
    "    },\n",
    "    {\n",
    "        \"demands\": [\"wind\"],\n",
    "        \"units\": [\"mph\"],\n",
    "        \"loc\": \"35.215, -97.519\"\n",
    "    }\n",
    "]\n",
    "\n",
    "tornado_model_vals = hazardsvc.post_tornado_hazard_values(tornado_model_id, points)\n",
    "print(json.dumps(tornado_model_vals, indent=4, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6ad9ea",
   "metadata": {},
   "source": [
    "#### 2.1.3 Creating a dataset-driven tornado\n",
    "\n",
    "If you have a deterministic tornado dataset available outside IN-CORE, you can use **pyincore** to create a tornado dataset on the serivce. In this section, we present an example of how to do this.\n",
    "\n",
    "The first step is to construct a hazard dataset description using JSON. In this example, we are creating a tornado dataset in Joplin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "tornado_dataset_data = {\n",
    "  \"name\": \"Joplin Dataset Tornado - workshop\",\n",
    "  \"description\": \"Joplin tornado hazard with shapefile\",\n",
    "  \"tornadoType\": \"dataset\"\n",
    "}\n",
    "\n",
    "tornado_dataset_json = json.dumps(tornado_dataset_data, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caee454",
   "metadata": {},
   "source": [
    "We also specify where the dataset files can be located (in our case, they have been provided to you in the local\n",
    "directory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b15df1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T23:15:11.804251Z",
     "start_time": "2023-11-08T23:15:11.792344Z"
    }
   },
   "outputs": [],
   "source": [
    "# zip file containing tornado path\n",
    "file_paths = [\"data/hazard/tornado/joplin_path_wgs84.shp\",\n",
    "              \"data/hazard/tornado/joplin_path_wgs84.dbf\",\n",
    "              \"data/hazard/tornado/joplin_path_wgs84.prj\",\n",
    "              \"data/hazard/tornado/joplin_path_wgs84.shx\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdec1a5",
   "metadata": {},
   "source": [
    "Using both the files and the JSON, we create a *scenario* tornado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e87805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tornado with definition and file\n",
    "dataset_response = hazardsvc.create_tornado_scenario(tornado_dataset_json, file_paths)\n",
    "print(json.dumps(dataset_response, indent=4, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9798c6f3",
   "metadata": {},
   "source": [
    "Similarly, we obtain the identifier of the output to the request (to ```HazardService```):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee8a45d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Display the path on the interactive map\n",
    "\n",
    "wsviz.show_tornado(client, dataset_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f08693b",
   "metadata": {},
   "source": [
    "Finally, we obtain the hazard values as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d90910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting hazard value from your dataset-based tornado\n",
    "points = [\n",
    "    {\n",
    "        \"demands\": [\"wind\"],\n",
    "        \"units\": [\"mph\"],\n",
    "        \"loc\": \"37.066, -94.502\"\n",
    "    },\n",
    "    {\n",
    "        \"demands\": [\"wind\"],\n",
    "        \"units\": [\"mph\"],\n",
    "        \"loc\": \"37.032, -94.348\"\n",
    "    }\n",
    "]\n",
    "\n",
    "tornado_dataset_id = dataset_response['id']\n",
    "tornado_dataset_vals = hazardsvc.post_tornado_hazard_values(tornado_dataset_id, points)\n",
    "print(json.dumps(tornado_dataset_vals, indent=4, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2692b7a",
   "metadata": {},
   "source": [
    "### 2.2. Earthquake hazards\n",
    "\n",
    "Similar to Tornado in the last section, we will now replicate these steps for a different type of hazard: earthquakes. We will look at both model-based and database driven hazard scenarios (deterministic and probabilistic)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c22b07b",
   "metadata": {},
   "source": [
    "#### 2.2.1 Working with existing earthquake hazards\n",
    "\n",
    "For this case, we will obtain metadata and hazard values for a 7.9 earthquake in Memphis, TN. Since we already have started\n",
    "the ```IncoreClient``` and ```HazardService objects```, we will not replicate the code here. Similar to Tornado, we can locate the hazard we want to work with by using the Hazard Viewer here: https://incore.ncsa.illinois.edu/HazardViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b300fa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T21:57:07.606222Z",
     "start_time": "2023-11-08T21:57:07.471058Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example earthquake in Memphis, TN\n",
    "example_earthquake_id = '5b902cb273c3371e1236b36b'\n",
    "\n",
    "# Obtain and display metadata\n",
    "earthquake_model_metadata = hazardsvc.get_earthquake_hazard_metadata(example_earthquake_id)\n",
    "print(json.dumps(earthquake_model_metadata, indent=4, sort_keys=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53e9c7-dba4-4159-8ce2-db5107089e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_earthquake(example_earthquake_id, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818bfea-96ef-42e1-8551-4ba7e2fdacdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display histogram of EQ\n",
    "wsviz.show_eq_hist(client, earthquake_model_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ea76b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hazard values\n",
    "points = [\n",
    "    {\n",
    "        \"demands\": [\"0.2 SA\"],\n",
    "        \"units\": [\"g\"],\n",
    "        \"loc\": \"35.07899, -90.0178\"\n",
    "    },\n",
    "    {\n",
    "        \"demands\": [\"0.2 SA\", \"PGA\", \"0.8 SA\"],\n",
    "        \"units\": [\"g\", \"g\", \"g\"],\n",
    "        \"loc\": \"35.027, -90.077\"\n",
    "    }\n",
    "]\n",
    "earthquake_model_vals = hazardsvc.post_earthquake_hazard_values(example_earthquake_id, points)\n",
    "print(json.dumps(earthquake_model_vals, indent=4, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a763e3bd",
   "metadata": {},
   "source": [
    "#### 2.2.2 Creating model-based earthquakes\n",
    "\n",
    "Similar to the case of tornadoes, it is possible to create new model-based earthquakes through JSON parameters.\n",
    "\n",
    "\n",
    "* *attenuations* - attenuation models capture how energy is lost as seismic waves propagate. At present, IN-CORE supports\n",
    "the following ones:\n",
    "  * AbrahamsonSilvaKamai2014\n",
    "  * AtkinsonBoore1995\n",
    "  * CampbellBozorgnia2014\n",
    "  * ChiouYoungs2014\n",
    "  * SadighChangEganMakdisiYoung1997\n",
    "* *earthquake position (lat, lon), depth and magnitude* - a description of the location and geophysical properties of\n",
    "the seismic event\n",
    "* *demand type and demand units* - a description of the quantity of interest and its units.\n",
    "\n",
    "Following known steps for model-based tornados, we request computation of a new Memphis earthquake. In this case,\n",
    "we decrease the depth to 7.0 km and decrease the intensity to 6.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaa580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new earthquake\n",
    "eq_model_metadata = {\n",
    "  \"name\": \"Memphis EQ Model (modified)\",\n",
    "  \"description\": \"Memphis model based hazard\",\n",
    "  \"eqType\": \"model\",\n",
    "  \"attenuations\" : {\n",
    "    \"AtkinsonBoore1995\" : \"1.0\"\n",
    "  },\n",
    "  \"eqParameters\" : {\n",
    "    \"srcLatitude\" : \"35.927\",\n",
    "    \"srcLongitude\" : \"-89.919\",\n",
    "    \"magnitude\" : \"6.5\",\n",
    "    \"depth\" : \"7.0\"\n",
    "  },\n",
    "  \"visualizationParameters\" : {\n",
    "    \"demandType\" : \"PGA\",\n",
    "    \"demandUnits\" : \"g\",\n",
    "    \"minX\" :\"-90.3099\",\n",
    "    \"minY\" :\"34.9942\",\n",
    "    \"maxX\" : \"-89.6231\",\n",
    "    \"maxY\" : \"35.4129\",\n",
    "    \"numPoints\" : \"1025\",\n",
    "    \"amplifyHazard\": \"true\"\n",
    "  }\n",
    "}\n",
    "\n",
    "eq_model_json = json.dumps(eq_model_metadata, indent=4)\n",
    "\n",
    "# Create an earthquake with definition\n",
    "eq_model_response = hazardsvc.create_earthquake(eq_model_json)\n",
    "\n",
    "print(json.dumps(eq_model_response, indent=4, sort_keys=False))\n",
    "\n",
    "# Acquire hazard id you created\n",
    "eq_model_id = eq_model_response['id']\n",
    "\n",
    "# Plot the earthquake\n",
    "viz.plot_earthquake(eq_model_id, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1ccc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting hazard value from your model based earthquake\n",
    "\n",
    "points = [\n",
    "    {\n",
    "        \"demands\": [\"0.2 SA\"],\n",
    "        \"units\": [\"g\"],\n",
    "        \"loc\": \"35.07899, -90.0178\"\n",
    "    },\n",
    "    {\n",
    "        \"demands\": [\"0.2 SA\"],\n",
    "        \"units\": [\"g\"],\n",
    "        \"loc\": \"35.027, -90.077\"\n",
    "    },\n",
    "]\n",
    "\n",
    "eq_model_vals = hazardsvc.post_earthquake_hazard_values(eq_model_id, points)\n",
    "print(json.dumps(eq_model_vals, indent=4, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e04e9",
   "metadata": {},
   "source": [
    "#### 2.2.3 Creating a dataset-driven earthquake (Probabilistic & Deterministic)\n",
    "\n",
    "Finally, we show how datasets can be used to create earthquake scenarios. In this case, both deterministic and probabilistic\n",
    "alternatives are available. We concentrate here on a deterministic example.\n",
    "\n",
    "For the example below, the earthquake datasets are provided as TIFF files.\n",
    "\n",
    "As with the corresponding tornado example, specify the dataset(s) to be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b4b09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_dataset_data = {\n",
    "  \"name\":\"Memphis Deterministic EQ\",\n",
    "  \"description\":\"Memphis dataset based deterministic hazard\",\n",
    "  \"eqType\":\"dataset\",\n",
    "  \"hazardDatasets\":[\n",
    "    {\n",
    "      \"hazardType\":\"deterministic\",\n",
    "      \"demandType\":\"SA\",\n",
    "      \"demandUnits\":\"g\",\n",
    "      \"period\":\"0.2\",\n",
    "      \"eqParameters\":{\n",
    "        \"srcLatitude\":\"35.927\",\n",
    "        \"srcLongitude\":\"-89.919\",\n",
    "        \"magnitude\":\"7.9\",\n",
    "        \"depth\":\"10.0\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"hazardType\":\"deterministic\",\n",
    "      \"demandType\":\"PGA\",\n",
    "      \"demandUnits\":\"g\",\n",
    "      \"period\":\"0.0\",\n",
    "      \"eqParameters\":{\n",
    "        \"srcLatitude\":\"35.927\",\n",
    "        \"srcLongitude\":\"-89.919\",\n",
    "        \"magnitude\":\"7.9\",\n",
    "        \"depth\":\"10.0\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "eq_dataset_json = json.dumps(eq_dataset_data, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c423d2",
   "metadata": {},
   "source": [
    "Similarly, specify where dataset files live:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b0291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T23:15:30.257245Z",
     "start_time": "2023-11-08T23:15:30.241403Z"
    }
   },
   "outputs": [],
   "source": [
    "file_paths = [\"data/hazard/earthquake/eq-dataset-SA.tif\", \"data/hazard/earthquake/eq-dataset-PGA.tif\"] \n",
    "# order should be same as the hazardDatasets from above json\n",
    "# eq-dataset-SA.tif represents 0.2 SA & eq-dataset-PGA.tif represents PGA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f908467",
   "metadata": {},
   "source": [
    "And finally, we create the earthquake and obtain hazard values from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c31bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an dataset-based earthquake with definition and files\n",
    "eq_dataset_response = hazardsvc.create_earthquake(eq_dataset_json, file_paths)\n",
    "print(json.dumps(eq_dataset_response, indent=4, sort_keys=False))\n",
    "\n",
    "# Acquire hazard id from recently created hazard\n",
    "eq_dataset_id = eq_dataset_response['id']\n",
    "viz.plot_earthquake(eq_dataset_id, client, \"0.2 SA\")\n",
    "viz.plot_earthquake(eq_dataset_id, client, \"PGA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c622013c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Obtain hazard value from your dataset-based earthquakes\n",
    "points = [\n",
    "    {\n",
    "        \"demands\": [\"0.2 SA\"],\n",
    "        \"units\": [\"g\"],\n",
    "        \"loc\": \"35.07899, -90.0178\"\n",
    "    },\n",
    "    {\n",
    "        \"demands\": [\"PGA\"],\n",
    "        \"units\": [\"g\"],\n",
    "        \"loc\": \"35.027, -90.077\"\n",
    "    },\n",
    "]\n",
    "eq_dataset_vals = hazardsvc.post_earthquake_hazard_values(eq_dataset_id, points)\n",
    "print(json.dumps(eq_dataset_vals, indent=4, sort_keys=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "089ac2c0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3. Working with Local Hazards\n",
    "This section shows how to work with local hazards including tornadoes, earthquakes, tsunamis, floods, and hurricanes. It also has some example visualizations for tornadoes and earthquakes. \n",
    "\n",
    "**pyincore** has several local hazard modules that enable users to perform analyses, tests, and visualization using data on their local machine without relying on the **HazardService**. The available modules are:  Hurricane, Flood, Earthquake, Tornado, and Tsunamis. These modules allow a user to read local data into a hazard object and pass that object to **pyincore** analyses to obtain hazard information from the local data instead of the **HazardService**. We'll see more on this later in session 4.\n",
    "\n",
    "![local_remote_hazard.png](data/local_remote_hazard.png)\n",
    "\n",
    "To get started, we need to import the local hazard modules we'll be working with as shown below.\n",
    "\n",
    "**Note** - local hazards currently support dataset (file) based only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d7b72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T22:39:29.561948Z",
     "start_time": "2023-11-08T22:39:29.553826Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# import local hazard modules\n",
    "from pyincore import Hurricane, Flood, Earthquake, Tornado, Tsunami"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fe045c-0ec0-440e-b63f-61146524645f",
   "metadata": {},
   "source": [
    "### 3.1 Basic Operations for Local Hazards\n",
    "Let's start with some basic operations for working with local hazards. Using the local hazard modules is straightforward. You can:\n",
    "1) Create a hazard by providing a JSON file that describes the hazard (metadata).\n",
    "2) Attach a dataset (file) to the hazard.\n",
    "3) Get hazard values from hazard object.\n",
    "\n",
    "For datasets, tornadoes use a Shapefile, while other hazards require a TIF (Tagged Image File) format. Now, let's see how each type of hazard works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc11c1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 3.1.1 Tornadoes\n",
    "**Inputs**: JSON representation of a dataset describing a tornado. Each available dataset in Shapefile format. For more information on the dataset type definition for a tornado, go here: https://incore.ncsa.illinois.edu/semantics/api/types/incore:tornadoWindfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d904f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T22:39:35.819562Z",
     "start_time": "2023-11-08T22:39:35.817512Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# indicate the path to the tornado dataset files\n",
    "dir = \"data/hazard/tornado/\"\n",
    "\n",
    "with open(os.path.join(dir, \"tornado_dataset.json\"), 'r') as file:\n",
    "    tornado_dataset_json = file.read()\n",
    "    print(json.dumps(json.loads(tornado_dataset_json), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ba9ef2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T22:42:49.641932Z",
     "start_time": "2023-11-08T22:42:49.597799Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create the tornado object\n",
    "tornado = Tornado.from_json_file(os.path.join(dir, \"tornado_dataset.json\"))\n",
    "\n",
    "# attach dataset from local file\n",
    "tornado.hazardDatasets[0].from_file((os.path.join(dir, \"joplin_path_wgs84.shp\")),\n",
    "                                    data_type=\"incore:tornadoWindfield\")\n",
    "\n",
    "payload = [\n",
    "    {\n",
    "        \"demands\": [\"wind\"],\n",
    "        \"units\": [\"mph\"],\n",
    "        \"loc\": \"-94.37, 37.04\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# get values\n",
    "values = tornado.read_hazard_values(payload, seed=1234) # removing the seed will give random values\n",
    "print(json.dumps(values, indent=4, sort_keys=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367823db",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 3.1.2 Earthquakes\n",
    "**Inputs**: JSON representation of a dataset describing an earthquake. Each available dataset in TIF format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4170033e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T22:43:11.072727Z",
     "start_time": "2023-11-08T22:43:11.063054Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# indicate the path\n",
    "dir = 'data/hazard/earthquake/'\n",
    "\n",
    "earthquake_dataset_json = ''\n",
    "with open(os.path.join(dir, \"eq-dataset.json\"), 'r') as file:\n",
    "    earthquake_dataset_json = file.read()\n",
    "    print(json.dumps(json.loads(earthquake_dataset_json), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818054e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T22:44:03.950701Z",
     "start_time": "2023-11-08T22:44:03.913578Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create the earthquake object\n",
    "eq = Earthquake.from_json_file(os.path.join(dir, \"eq-dataset.json\"))\n",
    "\n",
    "# attach datasets from local files\n",
    "eq.hazardDatasets[0].from_file((os.path.join(dir, \"eq-dataset-SA.tif\")),\n",
    "                               data_type=\"ergo:probabilisticEarthquakeRaster\")\n",
    "eq.hazardDatasets[1].from_file((os.path.join(dir, \"eq-dataset-PGA.tif\")),\n",
    "                               data_type=\"ergo:probabilisticEarthquakeRaster\")\n",
    "\n",
    "payload = [\n",
    "    {\n",
    "        \"demands\": [\"PGA\", \"0.2 SA\"],\n",
    "        \"units\": [\"g\", \"g\"],\n",
    "        \"loc\": \"35.03,-89.93\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# get values\n",
    "values = eq.read_hazard_values(payload)\n",
    "print(json.dumps(values, indent=4, sort_keys=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba7043",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 3.1.3 Tsunamis\n",
    "**Inputs**: JSON representation of a dataset describing a tsunami. Each available dataset in TIF format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2367a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T22:44:15.816620Z",
     "start_time": "2023-11-08T22:44:15.807179Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# indicate the path\n",
    "dir = 'data/hazard/tsunami/'\n",
    "\n",
    "with open(os.path.join(dir, \"tsunami.json\"), 'r') as file:\n",
    "    tsunami_dataset_json = file.read()\n",
    "    print(json.dumps(json.loads(tsunami_dataset_json), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d3617a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T22:44:17.746084Z",
     "start_time": "2023-11-08T22:44:17.729434Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create the tsunami object\n",
    "tsunami = Tsunami.from_json_file(os.path.join(dir, \"tsunami.json\"))\n",
    "\n",
    "# attach datasets from local files\n",
    "tsunami.hazardDatasets[0].from_file((os.path.join(dir, \"Tsu_100yr_Vmax.tif\")),\n",
    "                                    data_type=\"ncsa:probabilisticTsunamiRaster\")\n",
    "tsunami.hazardDatasets[1].from_file((os.path.join(dir, \"Tsu_100yr_Mmax.tif\")),\n",
    "                                    data_type=\"ncsa:probabilisticTsunamiRaster\")\n",
    "tsunami.hazardDatasets[2].from_file((os.path.join(dir, \"Tsu_100yr_Hmax.tif\")),\n",
    "                                    data_type=\"ncsa:probabilisticTsunamiRaster\")\n",
    "\n",
    "payload = [\n",
    "    {\n",
    "        \"demands\": [\"hmax\"],\n",
    "        \"units\": [\"m\"],\n",
    "        \"loc\": \"46.006,-123.935\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# get values\n",
    "values = tsunami.read_hazard_values(payload)\n",
    "print(json.dumps(values, indent=4, sort_keys=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba31d2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 3.1.4 Floods\n",
    "**Inputs**: JSON representation of a dataset describing a flood. Each available dataset in TIF format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62e11fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T22:44:27.874635Z",
     "start_time": "2023-11-08T22:44:27.865749Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# indicate the path\n",
    "dir = 'data/hazard/flood/'\n",
    "\n",
    "with open(os.path.join(dir, \"flood-dataset.json\"), 'r') as file:\n",
    "    flood_dataset_json = file.read()\n",
    "    print(json.dumps(json.loads(flood_dataset_json), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd8c327",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T22:44:30.806270Z",
     "start_time": "2023-11-08T22:44:30.789261Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create the flood object\n",
    "flood = Flood.from_json_file(os.path.join(dir, \"flood-dataset.json\"))\n",
    "\n",
    "# attach datasets from local files\n",
    "flood.hazardDatasets[0].from_file((os.path.join(dir, \"flood-inundationDepth-50ft.tif\")),\n",
    "                                  data_type=\"ncsa:probabilisticFloodRaster\")\n",
    "flood.hazardDatasets[1].from_file(os.path.join(dir, \"flood-WSE-50ft.tif\"),\n",
    "                                  data_type=\"ncsa:probabilisticFloodRaster\")\n",
    "\n",
    "payload = [\n",
    "    {\n",
    "         \"demands\": [\"waterSurfaceElevation\"],\n",
    "         \"units\": [\"m\"],\n",
    "         \"loc\": \"34.60,-79.16\"\n",
    "     }\n",
    " ]\n",
    "\n",
    "# get values\n",
    "values = flood.read_hazard_values(payload)\n",
    "print(json.dumps(values, indent=4, sort_keys=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53656f2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 3.1.5 Hurricanes\n",
    "**Inputs**: JSON representation of a dataset describing a hurricane. Each available dataset in TIF format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a4fa22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T22:44:40.489756Z",
     "start_time": "2023-11-08T22:44:40.480739Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# indicate the path\n",
    "dir = 'data/hazard/hurricane/'\n",
    "\n",
    "with open(os.path.join(dir, \"hurricane-dataset.json\"), 'r') as file:\n",
    "    hurricane_dataset_json = file.read()\n",
    "    print(json.dumps(json.loads(hurricane_dataset_json), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598f16e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T22:44:41.942725Z",
     "start_time": "2023-11-08T22:44:41.924117Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create the hurricane object\n",
    "hurricane = Hurricane.from_json_file((os.path.join(dir, \"hurricane-dataset.json\")))\n",
    "\n",
    "# attach datasets from local files\n",
    "hurricane.hazardDatasets[0].from_file((os.path.join(dir, \"Wave_Raster.tif\")),\n",
    "                                      data_type=\"ncsa:deterministicHurricaneRaster\")\n",
    "hurricane.hazardDatasets[1].from_file(os.path.join(dir, \"Surge_Raster.tif\"),\n",
    "                                      data_type=\"ncsa:deterministicHurricaneRaster\")\n",
    "hurricane.hazardDatasets[2].from_file(os.path.join(dir, \"Inundation_Raster.tif\"),\n",
    "                                      data_type=\"ncsa:deterministicHurricaneRaster\")\n",
    "\n",
    "payload = [\n",
    "        {\n",
    "            \"demands\": [\"waveHeight\", \"surgeLevel\"],\n",
    "            \"units\": [\"m\", \"m\"],\n",
    "            \"loc\": \"29.22,-95.06\"\n",
    "        },\n",
    "        {\n",
    "            \"demands\": [\"waveHeight\", \"surgeLevel\"],\n",
    "            \"units\": [\"cm\", \"cm\"],\n",
    "            \"loc\": \"29.23,-95.05\"\n",
    "        },\n",
    "        {\n",
    "            \"demands\": [\"waveHeight\", \"inundationDuration\"],\n",
    "            \"units\": [\"in\", \"hr\"],\n",
    "            \"loc\": \"29.22,-95.06\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# get values\n",
    "values = hurricane.read_hazard_values(payload)\n",
    "print(json.dumps(values, indent=4, sort_keys=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7aa7b4-3e49-4997-955b-98aa8e717132",
   "metadata": {},
   "source": [
    "### 3.2 Visualizations for Local Hazards\n",
    "In this section, we provide examples to show how to plot local tornadoes and earthquakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d14c8d9-d4f4-447d-a4b0-cbc00c545616",
   "metadata": {},
   "source": [
    "#### 3.2.1 Plotting a tornado\n",
    "In this example, we are using the identical tornado dataset discussed in Section 3.1.1. You will need to create a tornado object and attach the local shape file to the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a10b5-2985-4ce4-b20e-5078d82f693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate the path\n",
    "dir = \"data/hazard/tornado/\"\n",
    "\n",
    "# create the tornado object\n",
    "tornado = Tornado.from_json_file(os.path.join(dir, \"tornado_dataset.json\"))\n",
    "\n",
    "# attach dataset from local file\n",
    "tornado.hazardDatasets[0].from_file((os.path.join(dir, \"joplin_path_wgs84.shp\")),\n",
    "                                    data_type=\"incore:tornadoWindfield\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6d53b3-a0c2-4f4b-bc5e-3a5145e923fc",
   "metadata": {},
   "source": [
    "Then, we can plot the local shape file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99558632-f055-49f0-87fe-1ea766d09015",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = tornado.hazardDatasets[0].dataset.get_dataframe_from_shapefile()\n",
    "id_field = tornado.EF_RATING_FIELD\n",
    "\n",
    "map = viz.plot_gdf_map(gdf, id_field)\n",
    "map    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db502f38-db3b-4dee-a5c4-3fc58e16b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GeoDataframe.explore() to interact with the map\n",
    "gdf.explore(\n",
    "    column=\"ef_rating\", \n",
    "    tooltip=\"ef_rating\",  \n",
    "    popup=True,  \n",
    "    cmap=\"Set1\"  # use \"Set1\" matplotlib colormap)    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f09ac8-b4c3-4742-b2be-b6bd1cfcc199",
   "metadata": {},
   "source": [
    "#### 3.2.2 Plotting an Earthqauke \n",
    "In this example, we are using the identical earthquake dataset discussed in Section 3.1.2. Similary, you will need to create an earthquake object and attach the local tif files to the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f8c501-1755-4166-b750-ec87af77f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate the path\n",
    "dir = 'data/hazard/earthquake/'\n",
    "\n",
    "# create the earthquake object\n",
    "eq = Earthquake.from_json_file(os.path.join(dir, \"eq-dataset.json\"))\n",
    "\n",
    "# attach datasets from local files\n",
    "eq.hazardDatasets[0].from_file((os.path.join(dir, \"eq-dataset-SA.tif\")),\n",
    "                               data_type=\"ergo:probabilisticEarthquakeRaster\")\n",
    "eq.hazardDatasets[1].from_file((os.path.join(dir, \"eq-dataset-PGA.tif\")),\n",
    "                               data_type=\"ergo:probabilisticEarthquakeRaster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f317a-1e78-4286-935e-be150d6b8758",
   "metadata": {},
   "source": [
    "Then, we can plot the local tif files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30449d8-9e32-4134-8423-c3884e3436ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the earthquake\n",
    "for earthquake in eq.hazardDatasets:\n",
    "    demand_type = earthquake.demand_type\n",
    "    period = earthquake.period\n",
    "    title = \"Demand Type: \" + demand_type.upper() + \", Period: \" + str(period)\n",
    "    raster_file_path = earthquake.dataset.local_file_path\n",
    "\n",
    "    viz.plot_raster_file_with_legend(raster_file_path, title)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e936fcb1",
   "metadata": {},
   "source": [
    "## Session review\n",
    "\n",
    "With the experience gained in this session, you should now be able to:\n",
    "\n",
    "* Initialize ```IncoreClient``` and ```HazardService``` objects to authenticate to and access IN-CORE\n",
    "resources\n",
    "* Understand how to use **pyincore** modules to create and use existing hazards in the IN-CORE web service as well as obtain hazard values\n",
    "* Use **pyincore** local hazard modules to work local hazard data\n",
    "* Visualize local and remote hazards using **pyincore-viz** and **GeoPandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd1740e-eec8-4944-8ac2-680b24a5fe91",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Hands-on Assignment\n",
    "\n",
    "For the next part of this session, please open \"session2-assignment.ipynb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4006d1c-91fc-4d2e-9b78-43063c19b8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
